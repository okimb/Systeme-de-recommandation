{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommender_systeme.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okimb/Systeme-de-recommandation/blob/master/recommender_systeme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chy8HX4_WCe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvR-mylyWh1c",
        "colab_type": "code",
        "outputId": "8fdc6e2e-1f30-47f8-88ab-53113e349352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBC9Oh0UXRxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "DATA_SET_NAME = 'ml-20m'\n",
        "DATA_PATH = '/gdrive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlriozN2HIeZ",
        "colab_type": "text"
      },
      "source": [
        "**1. Nous avons téléchargé le data set Movilens 20M et nous l'avons chargé dans notre Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2DKf9M8aF1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "\n",
        "class DLProgress(tqdm):\n",
        "    \"\"\"\n",
        "    Handle Progress Bar while Downloading\n",
        "    \"\"\"\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        \"\"\"\n",
        "        A hook function that will be called once on establishment of the network connection and\n",
        "        once after each block read thereafter.\n",
        "        \"\"\"\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "        \n",
        "def download_extract():\n",
        "    \"\"\"\n",
        "    Download and extract database\n",
        "    \"\"\"\n",
        "    url = 'http://files.grouplens.org/datasets/movielens/' + DATA_SET_NAME + '.zip'\n",
        "    \n",
        "    if not os.path.exists(DATA_PATH):\n",
        "        os.makedirs(DATA_PATH)\n",
        "    \n",
        "    file_path = os.path.join(DATA_PATH, DATA_SET_NAME + '.zip')\n",
        "    \n",
        "    # download data:\n",
        "    if not os.path.exists(file_path):\n",
        "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading ml-20m.zip') as pbar:\n",
        "            urlretrieve(\n",
        "                url,\n",
        "                file_path,\n",
        "                pbar.hook)\n",
        "    else:\n",
        "        return\n",
        "    \n",
        "    print('Extracting data...')\n",
        "    with zipfile.ZipFile(file_path) as zf:\n",
        "        zf.extractall(DATA_PATH)\n",
        "\n",
        "    print('Done.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo_xiiTvH6J8",
        "colab_type": "text"
      },
      "source": [
        "**2. Chargement et prévisualisation des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y9wpnH2bhSt",
        "colab_type": "code",
        "outputId": "83069bbe-a0ed-413f-9210-12c5b3e90542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print('movies.csv: ')\n",
        "movies = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'movies.csv'),index_col=None)\n",
        "movies.describe()\n",
        "movies.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movies.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  ...                                       genres\n",
              "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1        2  ...                   Adventure|Children|Fantasy\n",
              "2        3  ...                               Comedy|Romance\n",
              "3        4  ...                         Comedy|Drama|Romance\n",
              "4        5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oove2Lzgeii-",
        "colab_type": "code",
        "outputId": "6666077f-e821-42cc-a2ab-fcaae5d8b01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print('ratings.csv: ')\n",
        "ratings = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'ratings.csv'),index_col=None)\n",
        "ratings.describe()\n",
        "ratings.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112486027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1        2     3.5  1112486027\n",
              "1       1       29     3.5  1112484676\n",
              "2       1       32     3.5  1112484819\n",
              "3       1       47     3.5  1112484727\n",
              "4       1       50     3.5  1112484580"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNXbCNhDezFx",
        "colab_type": "code",
        "outputId": "4d0fe428-335d-484c-ce9e-dce2d833450a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print('tags.csv: ')\n",
        "tags = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'tags.csv'),index_col=None)\n",
        "tags.describe()\n",
        "tags.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tags.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>tag</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>4141</td>\n",
              "      <td>Mark Waters</td>\n",
              "      <td>1240597180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65</td>\n",
              "      <td>208</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>1368150078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>353</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>1368150079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65</td>\n",
              "      <td>521</td>\n",
              "      <td>noir thriller</td>\n",
              "      <td>1368149983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65</td>\n",
              "      <td>592</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>1368150078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId            tag   timestamp\n",
              "0      18     4141    Mark Waters  1240597180\n",
              "1      65      208      dark hero  1368150078\n",
              "2      65      353      dark hero  1368150079\n",
              "3      65      521  noir thriller  1368149983\n",
              "4      65      592      dark hero  1368150078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASH0D4Gte5E5",
        "colab_type": "code",
        "outputId": "fb0f14af-78c7-4538-8402-4a518b54aa28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print('genome-tags.csv: ')\n",
        "genome_tags = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'genome-tags.csv'),index_col=None)\n",
        "genome_tags.describe()\n",
        "genome_tags.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "genome-tags.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tagId</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>007 (series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18th century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1920s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1930s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tagId           tag\n",
              "0      1           007\n",
              "1      2  007 (series)\n",
              "2      3  18th century\n",
              "3      4         1920s\n",
              "4      5         1930s"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0MvRw8GfDXR",
        "colab_type": "code",
        "outputId": "4cc835f4-25a0-4a64-ccff-2a3bc9cdc2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print('genome-scores.csv: ')\n",
        "genome_scores = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'genome-scores.csv'),index_col=None)\n",
        "genome_scores.describe()\n",
        "genome_scores.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "genome-scores.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.02500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.05775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.09675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.14675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  tagId  relevance\n",
              "0        1      1    0.02500\n",
              "1        1      2    0.02500\n",
              "2        1      3    0.05775\n",
              "3        1      4    0.09675\n",
              "4        1      5    0.14675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLscXk8-fdxX",
        "colab_type": "text"
      },
      "source": [
        "**3. Simples tatistiques sur les données**\n",
        "\n",
        " Cette statistique nous aidera à mieux comprendre nes données.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKvR5F-ofrEr",
        "colab_type": "code",
        "outputId": "237642c4-06b8-452f-c117-9114d351630d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print('The number of movies: {}'.format(movies.count()['movieId']))\n",
        "print('The number of ratings: {}'.format(ratings.count()['movieId']))\n",
        "\n",
        "print('')\n",
        "print('min value of rating: {}'.format(ratings['rating'].min()))\n",
        "print('max value of rating: {}'.format(ratings['rating'].max()))\n",
        "\n",
        "print('')\n",
        "ra = ratings.groupby(ratings['userId']).count()\n",
        "print('The number of user in ratings.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of ratings per user in ratings.csv: {}'.format(ra['movieId'].min()))\n",
        "print('The maximun number of ratings per user in ratings.csv: {}'.format(ra['movieId'].max()))\n",
        "\n",
        "print('')\n",
        "ra = ratings.groupby(ratings['movieId']).count()\n",
        "print('The number of movies in ratings.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of ratings per movie in ratings.csv: {}'.format(ra['userId'].min()))\n",
        "print('The maximun number of ratings per movie in ratings.csv: {}'.format(ra['userId'].max()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of movies: 27278\n",
            "The number of ratings: 20000263\n",
            "\n",
            "min value of rating: 0.5\n",
            "max value of rating: 5.0\n",
            "\n",
            "The number of user in ratings.csv: 138493\n",
            "The minimum number of ratings per user in ratings.csv: 20\n",
            "The maximun number of ratings per user in ratings.csv: 9254\n",
            "\n",
            "The number of movies in ratings.csv: 26744\n",
            "The minimum number of ratings per movie in ratings.csv: 1\n",
            "The maximun number of ratings per movie in ratings.csv: 67310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaTzA_4Pf4rg",
        "colab_type": "code",
        "outputId": "170036c3-5e74-4623-fb6e-90c0d07d82d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print('The number of tags in tags.csv: {}'.format(tags.count()['userId']))\n",
        "print('The number of tags in genome-tags.csv: {}'.format(genome_tags.count()['tagId']))\n",
        "\n",
        "print('')\n",
        "ra = tags.groupby(tags['userId']).count()\n",
        "print('The number of user in tags.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of tags per user in tags.csv: {}'.format(ra['movieId'].min()))\n",
        "print('The maximun number of tags per user in tags.csv: {}'.format(ra['movieId'].max()))\n",
        "\n",
        "print('')\n",
        "ra = tags.groupby(tags['movieId']).count()\n",
        "print('The number of movies in tags.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of tags per movie in tags.csv: {}'.format(ra['userId'].min()))\n",
        "print('The maximun number of tags per movie in tags.csv: {}'.format(ra['userId'].max()))\n",
        "\n",
        "print('')\n",
        "tags_mer = pd.merge(tags, genome_tags, how='left', left_on='tag', right_on='tag')\n",
        "print('The number of tags in tags.csv but not in genome-tags.csv: {}'.format(tags_mer[(tags_mer['tagId'].isnull())].count()[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of tags in tags.csv: 465564\n",
            "The number of tags in genome-tags.csv: 1128\n",
            "\n",
            "The number of user in tags.csv: 7801\n",
            "The minimum number of tags per user in tags.csv: 1\n",
            "The maximun number of tags per user in tags.csv: 20356\n",
            "\n",
            "The number of movies in tags.csv: 19545\n",
            "The minimum number of tags per movie in tags.csv: 1\n",
            "The maximun number of tags per movie in tags.csv: 1994\n",
            "\n",
            "The number of tags in tags.csv but not in genome-tags.csv: 247993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMqw_x9ogR7B",
        "colab_type": "code",
        "outputId": "ec1427eb-d3ba-49ac-c580-205d9384d519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('The length of genome_scores.csv: {}'.format(genome_scores.count()['movieId']))\n",
        "print('max value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].max()))\n",
        "print('min value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].min()))\n",
        "\n",
        "print('')\n",
        "ra = genome_scores.groupby(genome_scores['movieId']).count()\n",
        "print('The number of movies in genome_scores.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].min()))\n",
        "print('The maximun number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].max()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of genome_scores.csv: 11709768\n",
            "max value of relevance from genome_scores.csv: 1.0\n",
            "min value of relevance from genome_scores.csv: 0.00024999999999997247\n",
            "\n",
            "The number of movies in genome_scores.csv: 10381\n",
            "The minimum number of tags per movie in genome_scores.csv: 1128\n",
            "The maximun number of tags per movie in genome_scores.csv: 1128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pCVvpA1gb6e",
        "colab_type": "code",
        "outputId": "66b5ea4f-0fd0-4b92-f064-a6219a60c7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Analysis the relevant data of movies in both genome_scores.csv and ratings.csv:\n",
        "\n",
        "genome_scores_group = genome_scores.groupby(genome_scores['movieId']).mean()\n",
        "ratings_group = ratings.groupby(ratings['movieId']).mean()\n",
        "rat_ge_merge = pd.merge(ratings_group, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
        "number = rat_ge_merge.count()[0]\n",
        "print('Number of movies in both genome_scores.csv and ratings.csv: {}. Take up {}% of ratings.csv'\\\n",
        "      .format(number, round(number/19545*100)))\n",
        "\n",
        "ratings_genome_merge = pd.merge(ratings, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
        "number = ratings_genome_merge.count()[0]\n",
        "print('Number of ratings where its movieId in genome_scores.csv: {}. Take up {}% of ratings.csv'\\\n",
        "      .format(number, round(number/20000263*100)))\n",
        "\n",
        "print('')\n",
        "ra = ratings_genome_merge.groupby(ratings_genome_merge['userId']).count()\n",
        "number = ra.count()[0]\n",
        "print('{} users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up {}% of ratings.csv'\\\n",
        "      .format(number, round(number/138493*100)))\n",
        "print('Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: {}'.format(ra['movieId'].min()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of movies in both genome_scores.csv and ratings.csv: 10370. Take up 53.0% of ratings.csv\n",
            "Number of ratings where its movieId in genome_scores.csv: 19800443. Take up 99.0% of ratings.csv\n",
            "\n",
            "138493 users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up 100.0% of ratings.csv\n",
            "Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJdEqwqBgpco",
        "colab_type": "text"
      },
      "source": [
        "**4. Hypotheses et model de l'apprentissage automatique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feMNiWxIg65m",
        "colab_type": "text"
      },
      "source": [
        "**4.1 Hypothèse**\n",
        "\n",
        "\n",
        "1.   Les balises de genome-tags.csv constituent l'ensemble complet des espaces vectoriels de balises. Les autres balises ne figurant pas dans génome-tags.csv sont des combinaisons linéaires de balises dans le génome-tags.csv.\n",
        "2.   La fonctionnalité des films peut être parfaitement représentée par des balises dans genome-tags.csv, telles que le vecteur de pertinence dans genome_scores.csv. Le vecteur de pertinence dans genome_scores.csv est correct et peut représenter la fonctionnalité de films;\n",
        "3.   Ignorer la qualité des films;\n",
        "4.   Nous ne pouvons pas obtenir d'autres informations sur les films en dehors de l'ensemble de données. Donc, nous n'utilisons pas links.csv;\n",
        "5.   La durée de sortie des films n’affecte pas\n",
        "6.    L'horodatage dans ratings.csv: et tags.csv n'affecte pas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPYIUDd3hKY4",
        "colab_type": "text"
      },
      "source": [
        "**Definition du Problème**\n",
        "\n",
        "Nous avons choisi un data set de 19800443 d'évaluation pour construire un modèle afin de pouvoir vérifier notre hypothèse. \n",
        "\n",
        "*   Ces 19800443 évaluations sont classifiées selons 10370 films différents et 138493 utilisateurs différents;\n",
        "*   Chaque film a un vecteur de pertinence unique;\n",
        "*   L'objectif prémier de notre travail c'est de predir les filmes à un utilisateur à travers son identifiant et l'identifiant d'un filme de son choix.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF0aYCe7hT4r",
        "colab_type": "text"
      },
      "source": [
        "**Creation de données d'entrainement**\n",
        "\n",
        "Nous avons subdivisé 19800443 données évaluées et classifées (du fichier genome_scores.csv selon movieId) en (80%) de données d'entrainement et en (20%) de données de test. Nous pouvons constater que les données test contient 99,86% des utilisateurs. le chargement des données pretraités se feront dans la cellule de code de la section suivant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA4mnenShl7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess data (You should run last code cell to get 'ratings_genome_merge')\n",
        "# The first column of features is userId, the next is movieId.\n",
        "# The only one column of target is rating.\n",
        "\n",
        "remove_fields = ['timestamp','tagId','relevance','rating']\n",
        "target = ratings_genome_merge['rating']\n",
        "feature = ratings_genome_merge.drop(remove_fields, axis=1)\n",
        "features = feature.values\n",
        "target = target.values\n",
        "\n",
        "genome_scores_dict = {}\n",
        "for i in range(10381):\n",
        "    m_id = -1\n",
        "    vec = []\n",
        "    for j in range(1128):\n",
        "        index = j + i * 1128\n",
        "        if m_id < 0:\n",
        "            m_id = genome_scores['movieId'][index]\n",
        "        assert genome_scores['movieId'][index] == m_id\n",
        "        assert genome_scores['tagId'][index] == j + 1\n",
        "        vec.append(genome_scores['relevance'][index])\n",
        "    genome_scores_dict[str(m_id)] = vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hegj49rmNzf",
        "colab_type": "code",
        "outputId": "e8cc6404-3009-4108-8cc5-007fe9e9e67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Actually, using train_test_split in here is not best. \n",
        "# The better method should split the data according the userId, which make sure every user is in the test set.\n",
        "# But here, let us make it easier and quickly ( We have already include 99.86% users).\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_features,test_features, train_target, test_target = train_test_split(features,  \n",
        "                                                           target,  \n",
        "                                                           test_size = 0.2,  \n",
        "                                                           random_state = 0)\n",
        "\n",
        "dict_t = {}\n",
        "dict_t['userId'] = test_features[:,0]\n",
        "dict_t['movieId'] = test_features[:,1]\n",
        "pd_data = pd.DataFrame.from_dict(dict_t)\n",
        "user_test = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
        "\n",
        "print('{}% users in test set ({} users)'.format(round(user_test/138493*100, 2), user_test ))\n",
        "\n",
        "dict_t = {}\n",
        "dict_t['userId'] = train_features[:,0]\n",
        "dict_t['movieId'] = train_features[:,1]\n",
        "pd_data = pd.DataFrame.from_dict(dict_t)\n",
        "user_train = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
        "\n",
        "print('{}% users in training set ({} users)'.format(round(user_train/138493*100, 2), user_train ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.86% users in test set (138294 users)\n",
            "100.0% users in training set (138493 users)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msCha34Jmd1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save preprocess data to '/gdrive/My Drive/verify_assumption.data'\n",
        "pickle.dump((train_features, test_features, train_target, test_target, genome_scores_dict), open('/gdrive/My Drive/verify_assumption.data', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4W427SunP7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load preprocess data from '/gdrive/My Drive/verify_assumption.data'\n",
        "train_features, test_features, train_target, test_target, genome_scores_dict = pickle.load(open('/gdrive/My Drive/verify_assumption.data', mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XvLpebmHFG4",
        "colab_type": "text"
      },
      "source": [
        "**4.4  construction du modèle**\n",
        "\n",
        "Si le vecteur de pertinence correspondant  au genome_scores.csv peut représenter les films, nous pouvons l’utiliser pour créer un modèle prédictif selons les note attribuée par les utilisateurs. Pour ceux, nous donnons un modèle simplde de l'apprentissage automatique. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2kqWYmMnr0v",
        "colab_type": "text"
      },
      "source": [
        "**les paramettres du model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFwDN8ujn1OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 768  # batch size \"taille du lot\"\n",
        "lr = 1e-3         # learning rate \"taux d'apprentissage\"\n",
        "feature_dim = 512 # Dimension of movie or user feature vector 'Dimension du film ou du vecteur de fonctionnalités utilisateur'\n",
        "Epoch = 6         # train epoch \"époque du train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bugE1peVn7tb",
        "colab_type": "text"
      },
      "source": [
        "**Model¶**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl7KvRg9oPaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Verify_Assumption_Model(nn.Module):\n",
        "    \"\"\"The whole model\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Verify_Assumption_Model, self).__init__()\n",
        "        self.emb_user = nn.Embedding(138493 + 1, 512, # use ratings['userId'].max()+1 instead of 138493+1 is better\n",
        "                            padding_idx=0)\n",
        "        \n",
        "        self.movie_transfrom = nn.Sequential(\n",
        "            nn.Linear(1128, 512),\n",
        "            nn.Tanh(), # activation function can not be the final layer of Sequential. But it can be the first one.\n",
        "            nn.Linear(512, 512)\n",
        "        )\n",
        "    \n",
        "    def forward(self, userId, movieVector):\n",
        "        v_user  = self.emb_user(userId)\n",
        "        v_movie = self.movie_transfrom(movieVector)\n",
        "        v_user.unsqueeze_(1)\n",
        "        v_movie.unsqueeze_(2)\n",
        "        return torch.bmm(v_user,v_movie)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dPv5wc9obXb",
        "colab_type": "code",
        "outputId": "484811db-668a-47aa-b2b1-6516124186ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "len_train_features = len(train_features)\n",
        "index = 0\n",
        "model = Verify_Assumption_Model()\n",
        "model.cuda()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduce=False, size_average=False)\n",
        "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                               lr=lr, weight_decay=0)\n",
        "losses = {'train':[], 'test':[]}\n",
        "\n",
        "for epoch_i in range(Epoch):\n",
        "    index = 0\n",
        "    while index <= len_train_features:\n",
        "        index_end = index + batch_size\n",
        "        if index_end >= len_train_features:\n",
        "            batch_train = train_features[index:len_train_features]\n",
        "            batch_train_target = train_target[index:len_train_features]\n",
        "        else:\n",
        "            batch_train = train_features[index:index_end]\n",
        "            batch_train_target = train_target[index:index_end]\n",
        "\n",
        "        #assert len(batch_train) == len(batch_train_target)\n",
        "\n",
        "        userId = batch_train[:,0]\n",
        "        movieId = batch_train[:,1]\n",
        "        movie_vec = []\n",
        "        for i in range(len(movieId)):\n",
        "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
        "\n",
        "\n",
        "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
        "        rating = rating.squeeze_(1).squeeze_(1)\n",
        "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        losses['train'].append(loss.detach().cpu().numpy())\n",
        "        opt.step()\n",
        "        if len(losses['train']) % 500 == 0:\n",
        "            print('Epoch {:>3} Batch {:>4}/15840354   train_loss = {:.3f}'.format(\n",
        "                        epoch_i,\n",
        "                        index,\n",
        "                        losses['train'][len(losses['train'])-1]))\n",
        "        index += batch_size\n",
        "        \n",
        "    #############################test#############################\n",
        "    \n",
        "    len_test_features = len(test_features)\n",
        "    index = 0\n",
        "\n",
        "    while index <= len_test_features:\n",
        "        index_end = index + batch_size\n",
        "        if index_end >= len_train_features:\n",
        "            batch_train = test_features[index:len_train_features]\n",
        "            batch_train_target = test_target[index:len_train_features]\n",
        "        else:\n",
        "            batch_train = test_features[index:index_end]\n",
        "            batch_train_target = test_target[index:index_end]\n",
        "\n",
        "        #assert len(batch_train) == len(batch_train_target)\n",
        "\n",
        "        userId = batch_train[:,0]\n",
        "        movieId = batch_train[:,1]\n",
        "        movie_vec = []\n",
        "        for i in range(len(movieId)):\n",
        "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
        "\n",
        "\n",
        "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
        "        rating = rating.squeeze_(1).squeeze_(1)\n",
        "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
        "\n",
        "        losses['test'].append(loss.detach().cpu().numpy())\n",
        "        if len(losses['test']) % 500 == 0:\n",
        "            print('Epoch {:>3} Batch {:>4}/3960089   test_loss = {:.3f}'.format(\n",
        "                        epoch_i,\n",
        "                        index,\n",
        "                        losses['test'][len(losses['test'])-1]))\n",
        "        index += batch_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch   0 Batch 383232/15840354   train_loss = 11533.780\n",
            "Epoch   0 Batch 767232/15840354   train_loss = 8228.780\n",
            "Epoch   0 Batch 1151232/15840354   train_loss = 4863.979\n",
            "Epoch   0 Batch 1535232/15840354   train_loss = 2620.337\n",
            "Epoch   0 Batch 1919232/15840354   train_loss = 2049.221\n",
            "Epoch   0 Batch 2303232/15840354   train_loss = 1910.178\n",
            "Epoch   0 Batch 2687232/15840354   train_loss = 1392.610\n",
            "Epoch   0 Batch 3071232/15840354   train_loss = 1405.845\n",
            "Epoch   0 Batch 3455232/15840354   train_loss = 1242.801\n",
            "Epoch   0 Batch 3839232/15840354   train_loss = 1350.883\n",
            "Epoch   0 Batch 4223232/15840354   train_loss = 1300.026\n",
            "Epoch   0 Batch 4607232/15840354   train_loss = 1369.943\n",
            "Epoch   0 Batch 4991232/15840354   train_loss = 1185.802\n",
            "Epoch   0 Batch 5375232/15840354   train_loss = 1209.570\n",
            "Epoch   0 Batch 5759232/15840354   train_loss = 1210.279\n",
            "Epoch   0 Batch 6143232/15840354   train_loss = 1245.999\n",
            "Epoch   0 Batch 6527232/15840354   train_loss = 1135.006\n",
            "Epoch   0 Batch 6911232/15840354   train_loss = 1163.557\n",
            "Epoch   0 Batch 7295232/15840354   train_loss = 1166.615\n",
            "Epoch   0 Batch 7679232/15840354   train_loss = 1076.774\n",
            "Epoch   0 Batch 8063232/15840354   train_loss = 1260.751\n",
            "Epoch   0 Batch 8447232/15840354   train_loss = 1083.842\n",
            "Epoch   0 Batch 8831232/15840354   train_loss = 1141.767\n",
            "Epoch   0 Batch 9215232/15840354   train_loss = 1145.193\n",
            "Epoch   0 Batch 9599232/15840354   train_loss = 1171.663\n",
            "Epoch   0 Batch 9983232/15840354   train_loss = 1101.706\n",
            "Epoch   0 Batch 10367232/15840354   train_loss = 1138.605\n",
            "Epoch   0 Batch 10751232/15840354   train_loss = 1187.828\n",
            "Epoch   0 Batch 11135232/15840354   train_loss = 1170.296\n",
            "Epoch   0 Batch 11519232/15840354   train_loss = 1282.803\n",
            "Epoch   0 Batch 11903232/15840354   train_loss = 1132.126\n",
            "Epoch   0 Batch 12287232/15840354   train_loss = 1153.507\n",
            "Epoch   0 Batch 12671232/15840354   train_loss = 1180.721\n",
            "Epoch   0 Batch 13055232/15840354   train_loss = 1065.738\n",
            "Epoch   0 Batch 13439232/15840354   train_loss = 1148.415\n",
            "Epoch   0 Batch 13823232/15840354   train_loss = 1026.890\n",
            "Epoch   0 Batch 14207232/15840354   train_loss = 852.770\n",
            "Epoch   0 Batch 14591232/15840354   train_loss = 1089.035\n",
            "Epoch   0 Batch 14975232/15840354   train_loss = 1092.689\n",
            "Epoch   0 Batch 15359232/15840354   train_loss = 969.709\n",
            "Epoch   0 Batch 15743232/15840354   train_loss = 1088.418\n",
            "Epoch   0 Batch 383232/3960089   test_loss = 1162.715\n",
            "Epoch   0 Batch 767232/3960089   test_loss = 1082.036\n",
            "Epoch   0 Batch 1151232/3960089   test_loss = 1270.984\n",
            "Epoch   0 Batch 1535232/3960089   test_loss = 1201.654\n",
            "Epoch   0 Batch 1919232/3960089   test_loss = 1199.003\n",
            "Epoch   0 Batch 2303232/3960089   test_loss = 1213.821\n",
            "Epoch   0 Batch 2687232/3960089   test_loss = 1087.051\n",
            "Epoch   0 Batch 3071232/3960089   test_loss = 1263.174\n",
            "Epoch   0 Batch 3455232/3960089   test_loss = 1234.527\n",
            "Epoch   0 Batch 3839232/3960089   test_loss = 1207.526\n",
            "Epoch   1 Batch 286464/15840354   train_loss = 1040.532\n",
            "Epoch   1 Batch 670464/15840354   train_loss = 942.560\n",
            "Epoch   1 Batch 1054464/15840354   train_loss = 925.723\n",
            "Epoch   1 Batch 1438464/15840354   train_loss = 1103.513\n",
            "Epoch   1 Batch 1822464/15840354   train_loss = 1082.377\n",
            "Epoch   1 Batch 2206464/15840354   train_loss = 1042.212\n",
            "Epoch   1 Batch 2590464/15840354   train_loss = 1095.703\n",
            "Epoch   1 Batch 2974464/15840354   train_loss = 1068.841\n",
            "Epoch   1 Batch 3358464/15840354   train_loss = 938.776\n",
            "Epoch   1 Batch 3742464/15840354   train_loss = 1071.339\n",
            "Epoch   1 Batch 4126464/15840354   train_loss = 954.558\n",
            "Epoch   1 Batch 4510464/15840354   train_loss = 978.575\n",
            "Epoch   1 Batch 4894464/15840354   train_loss = 1027.733\n",
            "Epoch   1 Batch 5278464/15840354   train_loss = 983.691\n",
            "Epoch   1 Batch 5662464/15840354   train_loss = 1005.134\n",
            "Epoch   1 Batch 6046464/15840354   train_loss = 1085.628\n",
            "Epoch   1 Batch 6430464/15840354   train_loss = 1087.699\n",
            "Epoch   1 Batch 6814464/15840354   train_loss = 1015.486\n",
            "Epoch   1 Batch 7198464/15840354   train_loss = 1086.109\n",
            "Epoch   1 Batch 7582464/15840354   train_loss = 985.164\n",
            "Epoch   1 Batch 7966464/15840354   train_loss = 1142.946\n",
            "Epoch   1 Batch 8350464/15840354   train_loss = 1001.301\n",
            "Epoch   1 Batch 8734464/15840354   train_loss = 1033.006\n",
            "Epoch   1 Batch 9118464/15840354   train_loss = 1137.338\n",
            "Epoch   1 Batch 9502464/15840354   train_loss = 942.099\n",
            "Epoch   1 Batch 9886464/15840354   train_loss = 979.024\n",
            "Epoch   1 Batch 10270464/15840354   train_loss = 934.954\n",
            "Epoch   1 Batch 10654464/15840354   train_loss = 1071.100\n",
            "Epoch   1 Batch 11038464/15840354   train_loss = 1095.862\n",
            "Epoch   1 Batch 11422464/15840354   train_loss = 1133.550\n",
            "Epoch   1 Batch 11806464/15840354   train_loss = 998.591\n",
            "Epoch   1 Batch 12190464/15840354   train_loss = 1067.901\n",
            "Epoch   1 Batch 12574464/15840354   train_loss = 1112.874\n",
            "Epoch   1 Batch 12958464/15840354   train_loss = 1066.871\n",
            "Epoch   1 Batch 13342464/15840354   train_loss = 1013.898\n",
            "Epoch   1 Batch 13726464/15840354   train_loss = 1067.362\n",
            "Epoch   1 Batch 14110464/15840354   train_loss = 1185.626\n",
            "Epoch   1 Batch 14494464/15840354   train_loss = 999.857\n",
            "Epoch   1 Batch 14878464/15840354   train_loss = 941.784\n",
            "Epoch   1 Batch 15262464/15840354   train_loss = 1005.203\n",
            "Epoch   1 Batch 15646464/15840354   train_loss = 969.880\n",
            "Epoch   1 Batch 262656/3960089   test_loss = 1113.513\n",
            "Epoch   1 Batch 646656/3960089   test_loss = 1259.109\n",
            "Epoch   1 Batch 1030656/3960089   test_loss = 1198.869\n",
            "Epoch   1 Batch 1414656/3960089   test_loss = 1158.502\n",
            "Epoch   1 Batch 1798656/3960089   test_loss = 1208.950\n",
            "Epoch   1 Batch 2182656/3960089   test_loss = 1215.648\n",
            "Epoch   1 Batch 2566656/3960089   test_loss = 1157.954\n",
            "Epoch   1 Batch 2950656/3960089   test_loss = 1218.537\n",
            "Epoch   1 Batch 3334656/3960089   test_loss = 1112.343\n",
            "Epoch   1 Batch 3718656/3960089   test_loss = 1108.430\n",
            "Epoch   2 Batch 189696/15840354   train_loss = 911.577\n",
            "Epoch   2 Batch 573696/15840354   train_loss = 952.806\n",
            "Epoch   2 Batch 957696/15840354   train_loss = 925.772\n",
            "Epoch   2 Batch 1341696/15840354   train_loss = 929.677\n",
            "Epoch   2 Batch 1725696/15840354   train_loss = 915.624\n",
            "Epoch   2 Batch 2109696/15840354   train_loss = 946.714\n",
            "Epoch   2 Batch 2493696/15840354   train_loss = 983.926\n",
            "Epoch   2 Batch 2877696/15840354   train_loss = 1033.456\n",
            "Epoch   2 Batch 3261696/15840354   train_loss = 991.724\n",
            "Epoch   2 Batch 3645696/15840354   train_loss = 898.799\n",
            "Epoch   2 Batch 4029696/15840354   train_loss = 963.631\n",
            "Epoch   2 Batch 4413696/15840354   train_loss = 1092.414\n",
            "Epoch   2 Batch 4797696/15840354   train_loss = 1016.157\n",
            "Epoch   2 Batch 5181696/15840354   train_loss = 953.308\n",
            "Epoch   2 Batch 5565696/15840354   train_loss = 967.366\n",
            "Epoch   2 Batch 5949696/15840354   train_loss = 815.817\n",
            "Epoch   2 Batch 6333696/15840354   train_loss = 889.109\n",
            "Epoch   2 Batch 6717696/15840354   train_loss = 973.575\n",
            "Epoch   2 Batch 7101696/15840354   train_loss = 961.667\n",
            "Epoch   2 Batch 7485696/15840354   train_loss = 953.104\n",
            "Epoch   2 Batch 7869696/15840354   train_loss = 990.134\n",
            "Epoch   2 Batch 8253696/15840354   train_loss = 941.088\n",
            "Epoch   2 Batch 8637696/15840354   train_loss = 973.282\n",
            "Epoch   2 Batch 9021696/15840354   train_loss = 969.924\n",
            "Epoch   2 Batch 9405696/15840354   train_loss = 897.384\n",
            "Epoch   2 Batch 9789696/15840354   train_loss = 946.998\n",
            "Epoch   2 Batch 10173696/15840354   train_loss = 1009.972\n",
            "Epoch   2 Batch 10557696/15840354   train_loss = 791.493\n",
            "Epoch   2 Batch 10941696/15840354   train_loss = 930.917\n",
            "Epoch   2 Batch 11325696/15840354   train_loss = 988.497\n",
            "Epoch   2 Batch 11709696/15840354   train_loss = 950.003\n",
            "Epoch   2 Batch 12093696/15840354   train_loss = 1029.989\n",
            "Epoch   2 Batch 12477696/15840354   train_loss = 898.235\n",
            "Epoch   2 Batch 12861696/15840354   train_loss = 971.312\n",
            "Epoch   2 Batch 13245696/15840354   train_loss = 976.782\n",
            "Epoch   2 Batch 13629696/15840354   train_loss = 829.659\n",
            "Epoch   2 Batch 14013696/15840354   train_loss = 1083.712\n",
            "Epoch   2 Batch 14397696/15840354   train_loss = 946.495\n",
            "Epoch   2 Batch 14781696/15840354   train_loss = 935.606\n",
            "Epoch   2 Batch 15165696/15840354   train_loss = 926.185\n",
            "Epoch   2 Batch 15549696/15840354   train_loss = 988.195\n",
            "Epoch   2 Batch 142080/3960089   test_loss = 1107.587\n",
            "Epoch   2 Batch 526080/3960089   test_loss = 1198.743\n",
            "Epoch   2 Batch 910080/3960089   test_loss = 1048.132\n",
            "Epoch   2 Batch 1294080/3960089   test_loss = 1027.863\n",
            "Epoch   2 Batch 1678080/3960089   test_loss = 1129.913\n",
            "Epoch   2 Batch 2062080/3960089   test_loss = 1116.549\n",
            "Epoch   2 Batch 2446080/3960089   test_loss = 1094.541\n",
            "Epoch   2 Batch 2830080/3960089   test_loss = 1096.570\n",
            "Epoch   2 Batch 3214080/3960089   test_loss = 1215.546\n",
            "Epoch   2 Batch 3598080/3960089   test_loss = 1169.442\n",
            "Epoch   3 Batch 92928/15840354   train_loss = 1007.382\n",
            "Epoch   3 Batch 476928/15840354   train_loss = 1014.129\n",
            "Epoch   3 Batch 860928/15840354   train_loss = 876.598\n",
            "Epoch   3 Batch 1244928/15840354   train_loss = 894.006\n",
            "Epoch   3 Batch 1628928/15840354   train_loss = 954.695\n",
            "Epoch   3 Batch 2012928/15840354   train_loss = 1047.611\n",
            "Epoch   3 Batch 2396928/15840354   train_loss = 1005.629\n",
            "Epoch   3 Batch 2780928/15840354   train_loss = 957.135\n",
            "Epoch   3 Batch 3164928/15840354   train_loss = 877.355\n",
            "Epoch   3 Batch 3548928/15840354   train_loss = 870.801\n",
            "Epoch   3 Batch 3932928/15840354   train_loss = 845.984\n",
            "Epoch   3 Batch 4316928/15840354   train_loss = 841.425\n",
            "Epoch   3 Batch 4700928/15840354   train_loss = 841.466\n",
            "Epoch   3 Batch 5084928/15840354   train_loss = 1028.781\n",
            "Epoch   3 Batch 5468928/15840354   train_loss = 843.344\n",
            "Epoch   3 Batch 5852928/15840354   train_loss = 1010.257\n",
            "Epoch   3 Batch 6236928/15840354   train_loss = 978.831\n",
            "Epoch   3 Batch 6620928/15840354   train_loss = 1063.202\n",
            "Epoch   3 Batch 7004928/15840354   train_loss = 1029.719\n",
            "Epoch   3 Batch 7388928/15840354   train_loss = 1020.030\n",
            "Epoch   3 Batch 7772928/15840354   train_loss = 979.761\n",
            "Epoch   3 Batch 8156928/15840354   train_loss = 944.422\n",
            "Epoch   3 Batch 8540928/15840354   train_loss = 916.216\n",
            "Epoch   3 Batch 8924928/15840354   train_loss = 932.677\n",
            "Epoch   3 Batch 9308928/15840354   train_loss = 972.234\n",
            "Epoch   3 Batch 9692928/15840354   train_loss = 875.923\n",
            "Epoch   3 Batch 10076928/15840354   train_loss = 866.941\n",
            "Epoch   3 Batch 10460928/15840354   train_loss = 834.359\n",
            "Epoch   3 Batch 10844928/15840354   train_loss = 886.937\n",
            "Epoch   3 Batch 11228928/15840354   train_loss = 1004.515\n",
            "Epoch   3 Batch 11612928/15840354   train_loss = 1071.019\n",
            "Epoch   3 Batch 11996928/15840354   train_loss = 872.116\n",
            "Epoch   3 Batch 12380928/15840354   train_loss = 814.439\n",
            "Epoch   3 Batch 12764928/15840354   train_loss = 991.498\n",
            "Epoch   3 Batch 13148928/15840354   train_loss = 879.532\n",
            "Epoch   3 Batch 13532928/15840354   train_loss = 898.858\n",
            "Epoch   3 Batch 13916928/15840354   train_loss = 954.893\n",
            "Epoch   3 Batch 14300928/15840354   train_loss = 929.771\n",
            "Epoch   3 Batch 14684928/15840354   train_loss = 870.278\n",
            "Epoch   3 Batch 15068928/15840354   train_loss = 883.897\n",
            "Epoch   3 Batch 15452928/15840354   train_loss = 880.600\n",
            "Epoch   3 Batch 15836928/15840354   train_loss = 1157.510\n",
            "Epoch   3 Batch 21504/3960089   test_loss = 985.143\n",
            "Epoch   3 Batch 405504/3960089   test_loss = 1026.424\n",
            "Epoch   3 Batch 789504/3960089   test_loss = 1030.620\n",
            "Epoch   3 Batch 1173504/3960089   test_loss = 967.375\n",
            "Epoch   3 Batch 1557504/3960089   test_loss = 1019.800\n",
            "Epoch   3 Batch 1941504/3960089   test_loss = 1038.196\n",
            "Epoch   3 Batch 2325504/3960089   test_loss = 1002.651\n",
            "Epoch   3 Batch 2709504/3960089   test_loss = 1022.787\n",
            "Epoch   3 Batch 3093504/3960089   test_loss = 1143.577\n",
            "Epoch   3 Batch 3477504/3960089   test_loss = 1153.913\n",
            "Epoch   3 Batch 3861504/3960089   test_loss = 1052.508\n",
            "Epoch   4 Batch 380160/15840354   train_loss = 976.107\n",
            "Epoch   4 Batch 764160/15840354   train_loss = 1070.233\n",
            "Epoch   4 Batch 1148160/15840354   train_loss = 942.775\n",
            "Epoch   4 Batch 1532160/15840354   train_loss = 953.821\n",
            "Epoch   4 Batch 1916160/15840354   train_loss = 997.460\n",
            "Epoch   4 Batch 2300160/15840354   train_loss = 829.488\n",
            "Epoch   4 Batch 2684160/15840354   train_loss = 891.321\n",
            "Epoch   4 Batch 3068160/15840354   train_loss = 982.056\n",
            "Epoch   4 Batch 3452160/15840354   train_loss = 1145.158\n",
            "Epoch   4 Batch 3836160/15840354   train_loss = 915.189\n",
            "Epoch   4 Batch 4220160/15840354   train_loss = 1005.420\n",
            "Epoch   4 Batch 4604160/15840354   train_loss = 943.761\n",
            "Epoch   4 Batch 4988160/15840354   train_loss = 912.995\n",
            "Epoch   4 Batch 5372160/15840354   train_loss = 963.553\n",
            "Epoch   4 Batch 5756160/15840354   train_loss = 1109.768\n",
            "Epoch   4 Batch 6140160/15840354   train_loss = 1069.012\n",
            "Epoch   4 Batch 6524160/15840354   train_loss = 984.092\n",
            "Epoch   4 Batch 6908160/15840354   train_loss = 903.152\n",
            "Epoch   4 Batch 7292160/15840354   train_loss = 860.367\n",
            "Epoch   4 Batch 7676160/15840354   train_loss = 890.035\n",
            "Epoch   4 Batch 8060160/15840354   train_loss = 849.143\n",
            "Epoch   4 Batch 8444160/15840354   train_loss = 804.043\n",
            "Epoch   4 Batch 8828160/15840354   train_loss = 886.661\n",
            "Epoch   4 Batch 9212160/15840354   train_loss = 871.181\n",
            "Epoch   4 Batch 9596160/15840354   train_loss = 1015.981\n",
            "Epoch   4 Batch 9980160/15840354   train_loss = 898.283\n",
            "Epoch   4 Batch 10364160/15840354   train_loss = 1016.050\n",
            "Epoch   4 Batch 10748160/15840354   train_loss = 823.700\n",
            "Epoch   4 Batch 11132160/15840354   train_loss = 797.472\n",
            "Epoch   4 Batch 11516160/15840354   train_loss = 854.275\n",
            "Epoch   4 Batch 11900160/15840354   train_loss = 967.500\n",
            "Epoch   4 Batch 12284160/15840354   train_loss = 944.311\n",
            "Epoch   4 Batch 12668160/15840354   train_loss = 879.792\n",
            "Epoch   4 Batch 13052160/15840354   train_loss = 849.010\n",
            "Epoch   4 Batch 13436160/15840354   train_loss = 905.885\n",
            "Epoch   4 Batch 13820160/15840354   train_loss = 828.885\n",
            "Epoch   4 Batch 14204160/15840354   train_loss = 995.899\n",
            "Epoch   4 Batch 14588160/15840354   train_loss = 852.757\n",
            "Epoch   4 Batch 14972160/15840354   train_loss = 811.681\n",
            "Epoch   4 Batch 15356160/15840354   train_loss = 846.166\n",
            "Epoch   4 Batch 15740160/15840354   train_loss = 758.186\n",
            "Epoch   4 Batch 284928/3960089   test_loss = 999.340\n",
            "Epoch   4 Batch 668928/3960089   test_loss = 1041.351\n",
            "Epoch   4 Batch 1052928/3960089   test_loss = 1007.267\n",
            "Epoch   4 Batch 1436928/3960089   test_loss = 1101.091\n",
            "Epoch   4 Batch 1820928/3960089   test_loss = 1069.099\n",
            "Epoch   4 Batch 2204928/3960089   test_loss = 996.669\n",
            "Epoch   4 Batch 2588928/3960089   test_loss = 1001.820\n",
            "Epoch   4 Batch 2972928/3960089   test_loss = 1036.000\n",
            "Epoch   4 Batch 3356928/3960089   test_loss = 1060.006\n",
            "Epoch   4 Batch 3740928/3960089   test_loss = 932.030\n",
            "Epoch   5 Batch 283392/15840354   train_loss = 937.286\n",
            "Epoch   5 Batch 667392/15840354   train_loss = 909.451\n",
            "Epoch   5 Batch 1051392/15840354   train_loss = 810.420\n",
            "Epoch   5 Batch 1435392/15840354   train_loss = 848.891\n",
            "Epoch   5 Batch 1819392/15840354   train_loss = 924.958\n",
            "Epoch   5 Batch 2203392/15840354   train_loss = 755.522\n",
            "Epoch   5 Batch 2587392/15840354   train_loss = 929.344\n",
            "Epoch   5 Batch 2971392/15840354   train_loss = 841.372\n",
            "Epoch   5 Batch 3355392/15840354   train_loss = 974.840\n",
            "Epoch   5 Batch 3739392/15840354   train_loss = 949.286\n",
            "Epoch   5 Batch 4123392/15840354   train_loss = 865.488\n",
            "Epoch   5 Batch 4507392/15840354   train_loss = 879.840\n",
            "Epoch   5 Batch 4891392/15840354   train_loss = 841.867\n",
            "Epoch   5 Batch 5275392/15840354   train_loss = 885.666\n",
            "Epoch   5 Batch 5659392/15840354   train_loss = 835.153\n",
            "Epoch   5 Batch 6043392/15840354   train_loss = 779.458\n",
            "Epoch   5 Batch 6427392/15840354   train_loss = 1112.644\n",
            "Epoch   5 Batch 6811392/15840354   train_loss = 973.768\n",
            "Epoch   5 Batch 7195392/15840354   train_loss = 936.246\n",
            "Epoch   5 Batch 7579392/15840354   train_loss = 900.856\n",
            "Epoch   5 Batch 7963392/15840354   train_loss = 983.173\n",
            "Epoch   5 Batch 8347392/15840354   train_loss = 1026.114\n",
            "Epoch   5 Batch 8731392/15840354   train_loss = 894.488\n",
            "Epoch   5 Batch 9115392/15840354   train_loss = 900.005\n",
            "Epoch   5 Batch 9499392/15840354   train_loss = 830.781\n",
            "Epoch   5 Batch 9883392/15840354   train_loss = 1003.391\n",
            "Epoch   5 Batch 10267392/15840354   train_loss = 858.567\n",
            "Epoch   5 Batch 10651392/15840354   train_loss = 887.252\n",
            "Epoch   5 Batch 11035392/15840354   train_loss = 908.688\n",
            "Epoch   5 Batch 11419392/15840354   train_loss = 1116.582\n",
            "Epoch   5 Batch 11803392/15840354   train_loss = 856.458\n",
            "Epoch   5 Batch 12187392/15840354   train_loss = 908.750\n",
            "Epoch   5 Batch 12571392/15840354   train_loss = 932.226\n",
            "Epoch   5 Batch 12955392/15840354   train_loss = 850.137\n",
            "Epoch   5 Batch 13339392/15840354   train_loss = 880.645\n",
            "Epoch   5 Batch 13723392/15840354   train_loss = 877.099\n",
            "Epoch   5 Batch 14107392/15840354   train_loss = 1134.026\n",
            "Epoch   5 Batch 14491392/15840354   train_loss = 1019.135\n",
            "Epoch   5 Batch 14875392/15840354   train_loss = 896.732\n",
            "Epoch   5 Batch 15259392/15840354   train_loss = 988.219\n",
            "Epoch   5 Batch 15643392/15840354   train_loss = 1087.223\n",
            "Epoch   5 Batch 164352/3960089   test_loss = 1042.288\n",
            "Epoch   5 Batch 548352/3960089   test_loss = 999.568\n",
            "Epoch   5 Batch 932352/3960089   test_loss = 1124.684\n",
            "Epoch   5 Batch 1316352/3960089   test_loss = 1166.552\n",
            "Epoch   5 Batch 1700352/3960089   test_loss = 1041.437\n",
            "Epoch   5 Batch 2084352/3960089   test_loss = 1098.186\n",
            "Epoch   5 Batch 2468352/3960089   test_loss = 1015.788\n",
            "Epoch   5 Batch 2852352/3960089   test_loss = 1007.981\n",
            "Epoch   5 Batch 3236352/3960089   test_loss = 1202.213\n",
            "Epoch   5 Batch 3620352/3960089   test_loss = 1073.189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsHDZ3-GZBNF",
        "colab_type": "code",
        "outputId": "042bc058-7dd4-4fc4-9363-bc053df1e9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "plt.plot(losses['train'], label='Training loss')\n",
        "plt.legend()\n",
        "_ = plt.ylim()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-d74ba36c18c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7f1prxkYQa7",
        "colab_type": "code",
        "outputId": "987bc84a-afbc-431a-f694-9a42ad31aa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(losses['test'], label='test loss')\n",
        "plt.legend()\n",
        "_ = plt.ylim()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VFX6wPHvSSGRHkKvAaT3IkWU\nqtIUXHVXERVQF10V60+Jir2hrI1VUVdRsaBYVkGQItJUioB0UEKThBZaqAGSnN8fcyeZcqfXzLyf\n5+Fh5tw7956bSe57T1daa4QQQsSfhEhnQAghRGRIABBCiDglAUAIIeKUBAAhhIhTEgCEECJOSQAQ\nQog4JQFACCHilAQAIYSIUxIAhBAiTiVFOgPuVK1aVWdkZEQ6G0IIUaqsWrXqoNa6mqf9ojoAZGRk\nsHLlykhnQwghShWl1C5v9pMqICGEiFMSAIQQIk5JABBCiDgV1W0AQoj4cu7cObKzs8nPz490VkqF\n1NRU6tatS3Jysl+flwAghIga2dnZVKhQgYyMDJRSkc5OVNNac+jQIbKzs2nYsKFfx5AqICFE1MjP\nzyc9PV1u/l5QSpGenh5QaUkCgBAiqsjN33uB/qwkAARRYZFm2m+7KSgsinRWhBDCIwkAQTR1xV88\n9PU6Pvx1Z6SzIoTww9GjR3nrrbf8/vxrr73GqVOnTLf17t076ga2SgAIoqOnzgJwxPjfzLnCImat\n34vWOlzZEkJ4KZQBIBpJAAiz//yUxR2frmbepv0hO8eGnDwyMmeyZvfRkJ1DiFiUmZnJtm3baN++\nPQ8++CAAEyZM4IILLqBt27Y88cQTAJw8eZLBgwfTrl07WrduzRdffMHEiRPZs2cPffr0oU+fPm7P\nM3XqVNq0aUPr1q0ZO3YsAIWFhYwcOZLWrVvTpk0bXn31VQAmTpxIy5Ytadu2Ldddd11Qr1e6gYaA\nu4f7vUdPA3D01LmQnf+nLQcAmL95P+3rVQ7ZeYQIpadmbGTTnmNBPWbL2hV54opWLrePHz+eDRs2\nsGbNGgDmzp3L1q1bWbFiBVprhgwZwuLFi8nNzaV27drMnDkTgLy8PCpVqsQrr7zCggULqFq1qstz\n7Nmzh7Fjx7Jq1SrS0tK47LLL+Pbbb6lXrx45OTls2LABsJRGrHnasWMHKSkpxWnB4rEEoJSarJQ6\noJTaYLLtAaWUVkpVNd4rpdREpVSWUmqdUqqjzb4jlFJbjX8jgnoVUUJ6LwgRW+bOncvcuXPp0KED\nHTt2ZMuWLWzdupU2bdowb948xo4dy5IlS6hUqZLXx/ztt9/o3bs31apVIykpieHDh7N48WIaNWrE\n9u3bGTNmDLNnz6ZixYoAtG3bluHDh/PJJ5+QlBTcZ3ZvjvYh8AYwxTZRKVUPuAz4yyZ5INDE+NcV\nmAR0VUpVAZ4AOgMaWKWUmq61PhLoBZQ20Vrz/2vWQQq15uImHmeQFSIs3D2ph4vWmocffpjbbrvN\nadvq1auZNWsW48aNo1+/fjz++OMBnSstLY21a9cyZ84c3n77baZNm8bkyZOZOXMmixcvZsaMGTz3\n3HOsX78+aIHAYwlAa70YOGyy6VXgIezvaUOBKdpiGVBZKVUL6A/M01ofNm7684ABAec+Snlzk3/o\n63WcOlsQ8ry4cyz/HH3+vZANOXlc/95ybnx/RUTzI0SkVahQgePHjxe/79+/P5MnT+bEiRMA5OTk\ncODAAfbs2UPZsmW54YYbePDBB1m9erXp58106dKFRYsWcfDgQQoLC5k6dSq9evXi4MGDFBUVcfXV\nV/Pss8+yevVqioqK2L17N3369OHFF18kLy+vOC/B4FcYUUoNBXK01msdqj3qALtt3mcbaa7SzY49\nGhgNUL9+fX+yFzLZR07R9+VFzBxzEU1qVAj4eLnHz9AgPXTNMO7aIrTWjPvfBnYcPMlrP/4ZsjwI\nUZqkp6fTo0cPWrduzcCBA5kwYQKbN2+me/fuAJQvX55PPvmErKwsHnzwQRISEkhOTmbSpEkAjB49\nmgEDBlC7dm0WLFhgeo5atWoxfvx4+vTpg9aawYMHM3ToUNauXcuoUaMoKrKMI3rhhRcoLCzkhhtu\nIC8vD601d999N5UrB69dz+e7j1KqLPAIluqfoNNavwu8C9C5c+eQ15j8degUlcslUzHV82RKP6zf\nx9mCIr74bTfjLm/pcj+tYdehkzRIL2e6LdS8aYmYvWEf09fuCXlehChtPvvsM7v399xzD/fcc49d\nWuPGjenfv7/TZ8eMGcOYMWNMj7tw4cLi18OGDWPYsGF229u1a1dckrD1888/e5t1n/nTDbQx0BBY\nq5TaCdQFViulagI5QD2bfesaaa7SQ+6DX3aQkTmTcy5G5/acsICr3vrVLi0jcyYv/LDZ73O+u3gb\nvSYsZMs+9z0Ygh0Mjp46y+s/bqXI4bhaa6fqpsNuxir44sXZW8jInEmh40mjlIzSFqKEzwFAa71e\na11da52htc7AUp3TUWu9D5gO3GT0BuoG5Gmt9wJzgMuUUmlKqTQspYc5wbsM156asQmAU2cKXe6T\ndaCkTm33YcsgjncWbXfaTzvU7hcVaZZuO1T83lobZr0XZh8+7fEYjoqKNB8v28WZAtf5dXT45Fn+\n3H+c9k/P49Uf/2TRnwfstn/0605aPj6HnKPO+QnUe0ssP6dQB4BtuSeYtnK35x3d2H34FOc/+oPX\nx/lpy37mbtwX0DmFiGbedAOdCiwFmimlspVSt7jZfRawHcgC/gvcAaC1Pgw8A/xm/HvaSIs6PSeY\n19uZee/n7Qz77zIW/HHAdLvpLVG73/7d2hwe+3YDzcbN5utV2Xzwyw7W7j5Ki8dm8+LsLabnuezV\nRVz26uLi99absTXYzNpguYntOniyeASysqsoCrz76stz/2DXoZPsPnyKjMyZPPP9poCPaWvg60t4\n6Kt1AR0jK9cS6Geu2+vV/jd/uJLRH68K6JzCdzJK3nuB/qy86QU0TGtdS2udrLWuq7V+32F7htb6\noPFaa63v1Fo31lq30VqvtNlvstb6fOPfBwHl2h/K8nTtibufp+1N8/5pa3hp9h8AfLJ0F7nHz5gc\nq+Rgh06c4bmZmyjwkIfj+SVVNQ98uZanZmxi6Ju/cPpcIZMWbgMsT8PXTPq1+PgHTzhU5xhFkTcX\nbLNLvv695Twwba3b8/vKeonvLN7OzR/+xsY9eQC8//OOoJ7nbIFU3cSD1NRUDh06JEHAC9b1AFJT\nU/0+RtyMBF6yNZe7Pvude/o14b5Lmzpt11qTfcR9FYlt9c03q0uaMOZvOcAFz/1I42r2jb4HT5zl\nj33HaVazAo9P38jMdXspnxL4j7zfy4ss5918gEta1nDa7u55/pvfc3jl2vb2+9t8ICNzJjd2a8Az\nV7b2OV8FRdougBYUFnHiTAGVy5bx+VgiPtWtW5fs7Gxyc3MjnZVSwboimL/iJgBMmGN5Wn99/tbi\nAGBbIpi2cjdjv17v1bFcDfjdlnvS7v0j/7Mc7+0bOhU3PtrWlTs+5azceZj//JTlVR4ATp4t4MhJ\n9425eS6mnLC9Bsd5iT5etotnrmzNmYJCFmzJZUDrmi6Pb3sFjj+Wh79Zz5erstn63ECSE6Ng2imb\nzK7PzmPp9oOM7tk4cvkRTpKTk/1e3Ur4Lgr+KkNj6/7j/Jp1sPj9rkPOM/TN31JSd79ql/eDkn0t\nnd7+iXf1yNe8vdS0KsmVBKXo8Mw8t/sMfH2x39UnD0xby+2frOLXbZaf44ItB+j0zDzyz1kaqLOP\nnLILaI5TYXxndDONth5CSsEVb/zM87NK2lTGfrWOjMyZEcyViKRfsg7y3ZqwdEyMKjEbAC59dTHX\nv7fcdJv1Bmb9H8xv6hmZM5m13rsGQ2+56gXkTfuEI1clEdv0PXn5prOCfrUq2+2xx327nu+NxtJj\npy2liOdmbebQybPsPnyKA8fzuehF+wZzhXnD9nXvLmPK0p0AzN24z67XVSis2nWEE2e8H2W9+/Ap\nvgiwh5Eo3Ya/t5x7Pl8T6WyEXcwGAHeem7mZE2cKvJqy4Y5PnQdm+DPn25yNlmoW20DT9+VFjPzA\nMv3C2K997+Hy537zG6mn7D3+3QaPJZ5PlpVM8XT7J6v569ApuyqrWz40X9jCLpAar9fsPsrj323k\nXGERoz9exSWvLPKQQ/8dzz/H1ZN+5V9elroALn7Jfc8vf4KzEJ4UFWmen7WZPSHonu2tuAwAHy/b\nResn5vDN6pKn4Nlu+ntnZM7k8xV/udzuizMO1TEL/7A0dn3p4Yncaq3N0/zE+VtN91n9l/spY6cs\n3eXVuWz97/ec4oD5xoIs1ufkOe2z/eBJuxLOWYdBV8GoCjpqMoBt4vytxYP9rNVdG02mEf7Xp85B\nYdGfnhsbAxkUKIQrv+8+yruLt3PvF5ErecRlALCy3nzBvvulmcxvvGsgDrWhb/4SkfMWaV38RP/d\nGtdTSDh2PQ229k87t3m8s8hyTsfg6ij/nPP2EZPNJ8B7c0FJY/z3Xo4bEMIX1hJ1JNvI4joA+Ou/\nS4Lbx700eH3+VrYfPOlxv817A1/A4/TZQn7eetDl9l2HTvK1TYnp5FlLW45tFdVhD72jPLH2GrNV\nVKRp8+QcpgapNCiiz89bD4ZtDMIGk1J0uEkA8MFHv/pedeINX+qrSzNPf1fH8s+xZd8xHv12PTe8\nv5xtueZtHL0mLOSBL9c6Vd/8d8kOu7Ecrqa++G2Hb4PQ9+bls+PgSc4VFXE8v4CHv1lPRubMoA92\nE5F3w/vLva6ODdSTM4I7Wt4fEgB8EIq5dAB+2BAf883Ytg9Yx0jYuvG95Qx4bUlxL6ETRrWctQeR\no12H7EskE+dv5SabKp3DjiOkDdYSgy/6/HuhU9oHv0gAiAULHaZycTUgVGsdcx0CJACIiPhsuXM1\nytps8yLx499tNE0/eabQqaonlIvsqCDMmSSiy65DJxn5wW92aa6+5bs/X0OjR2aFPlNhJAFAhM2/\n53i38Iy1qmjom7/w3EzXxeT//LSVC5770S7tXGHJE5rtJH0vuZhIz9F7S7Zz4Fi+6TbH7r+yBHTp\n58t4kRnGwMYfN+13OQFkaSMBQITNZJMqk2XbD7HfxQ0X3De4nzpb6LYHxSvzLAHng1928NZC73on\nPTtzM12en2+6zfF+X1gYW9UBsWLM1N+Zv3m/5x0xb5eyBvY5G/cx4LXFTr9jt05ZySiHUoMrK3ce\ntlsXZNn2Q2zZd8zt73w4xc1cQCL63Pj+cpZsPUh6uTKseuzS4nSzMQb+2pCTV7wmRKCunmS/cJCn\nmV1FZMxYu4cZa/ewc/xgvz5vrer7vy/Xcjy/gBNnCqh0nvOKgZN/3kG7epXo1KCKy2Nd8/ZSgOK8\nXPfuMgDKlUm0OV/kSAlARMwSo6vnoZNnOXA8NE9El/8neMvpObZRhKMKSGttOpfT2YIi/tjnfvFx\n4ezU2QKvG3ILjBLe+0ucF4cCePr7TVw9aalXx8rInMnW/SXflz8dEUJBAoCICl2eM692iWa+TNxn\nVVSk2ZvnfW+y8bO30HTcD04rxD0xfQP9X1vMvrzoqEooDU6cKaDl43OYMLdkjIe7rsmnjbnCJv6U\nZTcC318zXAwoXLnrCOO+XR+R5UolAAjhJ39qgF6fv5XuL/xE9hHn2WnNTDV6S+Wftb85rNxpmcvp\nWL75dN/CmXVSw29/L5n102xyRrOSnTcj8Pfl5bu9iee4WW/kk2V/8aNNu0W4ArsEACHCaPFWy+C1\n/cd8Kz14WkvaX/uPWQa5xQKttd3YkIzMmRw5eZZpK3fbTQ1v67RJVYx1VTtfHDxxhm4vzOeqSb9y\nrrDItHPCjHWup1CBkjalb1Zn0+2F+azcGfpVcyUACBEERUWaFTsOc9LrboXe3dCtayy4qqpwTF+z\n+yiHTngfXLo+P990kFtpNG3lbnpNWGiXtjcvn4e+Wudyavi3Fzn3DpuzcT9D3vC+7Sjv1LniSQrX\nZefR5NEfaGwyXsDTuhx3ffY7AL8Zpbs/9oe+jUcCgBBBcO27S/nHO0u55/Pfg3pcx+qIjXvyGPnB\nCsvkfCaufPMXhrxRUl3xzqJtdhPbxTKzdS9su4Naf2KFRZopS3dytqDIdIJAsNzIvbVoq/mMsgd9\nCMS2wjnXVEx2A5UFpUW4WZ/aHKehzjl6mvxzhTSuVt7nY+afK+SosaSn9Td68ETPT6a2U5a88INl\nANztvRqTmFASTXYdOsnJM9HREyVYikzu5S/PKxl8ONuYcuXA8TM8/t1Gl8ul+n5e8/uNPyvxeTM9\neTDFZAlA7v8inPJOu76R9Bj/E/1eLlkAx1XP0S9X7qbTM/PsbiZv2Ty5B/pQk+mw4FCvCQsZNHFJ\nQMeMNp5Wdft46U679y/P+5O/DnvXGO/ODxv28uu2Q07p/nQTdjU9eajEZAAQIpyenG4+V5E7jvfz\nR/+3gUMnz3LO5jH2x80l0w18vGyX6ZrF3jYOh2uGy2i202Rd8GBM8Dhn436X81UFIhwPsrFZBRTp\nDIi4YruYkKs/2lW7DrsdMWpr9JSV/HX4FFtsBnq99qP56m+2+r280Kvji/CYUwpm+Y3NACB1QCJM\nPl62y77/tos5Xq6etJQHLm1avGrZNW8vZVCbmvRuVp3ujdKL9/ts+V/M3eTdPDZW+4/lU7ZMItty\nS7pAnjxTQKsn5vh0nFDKOnCCjXvyGNq+TqSzEjbRMN+/JzEZAIQIl2dM/shX7TpCq9oVSXCoBLZt\nkASYtX4fs9ZbnhLLJFpqY32dt0hrS1fOOpXPs0vfZVLd4Yu5G/exctcRHhnUIqDjWF3yiqUdJJ4C\nQKAW/5nLDd0ahPQcHgOAUmoycDlwQGvd2kibAFwBnAW2AaO01keNbQ8DtwCFwN1a6zlG+gDgdSAR\neE9rPT74l2Mhz/8iXMzq4B0njQsHx7psd20Drqa7tjX6Y8sqdcEKAMJ3vpYE/eFNI/CHwACHtHlA\na611W+BP4GEApVRL4DqglfGZt5RSiUqpROBNYCDQEhhm7BsSUgMkSpuzfs4D42o8gHVVNbt9izRa\na4b9d5nTNttqU8d5h2xNWriteJptUfp5DABa68XAYYe0uVpra8vXMqCu8Xoo8LnW+ozWegeQBXQx\n/mVprbdrrc8Cnxv7ClGqnYvwmgCuBnm9NNt5UftGj8zi2neX2bUVWNk+bc50MWkZwIuztzBxvucG\naVE6BKMb6M3AD8brOoBtZ9xsI81VuhOl1Gil1Eql1MrcXP8GRYRq3hQhoo21DcGRq+6NK3aYzy+z\nLbekxOBqBOt7LqZF9sRdiUJEVkABQCn1KFAAfBqc7IDW+l2tdWetdedq1aoF67BCCDdsSwzPzzJf\nPvPZmZv9OvaQ/3ieSVNEht+9gJRSI7E0DvfTJRWIOUA9m93qGmm4SQ86aQMQInoEa1KzwiJtN52F\nCJxfJQCjR89DwBCttW1/s+nAdUqpFKVUQ6AJsAL4DWiilGqolCqDpaF4emBZF0JEyoFj+UEZReut\nLfuO0fiRWXz7ew6nznq/kLtwz5tuoFOB3kBVpVQ28ASWXj8pwDxjutplWuvbtdYblVLTgE1Yqobu\n1FoXGse5C5iDpRvoZK118MdOCyHCosvzlhXc/F1311dr/rLM9HnvF2son5LEhqf6h+W8sc5jANBa\nDzNJft/N/s8Bz5mkzwKcJ8kOAakCEiJ89uadJq1sGVKTSxY6P5Z/jn4vL2LS8I5BOcc5m26yJ7xe\nc0F4EpOTwUkvICF85/1iNva6v/ATd3222i5t7e6j5B4/Y9od1R+R7m4bq2IyAAghfNf/tcU+f8a6\nWPqPmw/w05b9aK1ZsOVA8Vz4K/xY1nBv3mmWOCyyYnb73557gnXZgS/WHs9iMgBIFZAQvst2s2i5\nK7aLpd/84UomLdrGqA9/4w0XA9TOFhTR5sk5zFjren3cQa8v4cb37efFN5vgse/Lixjyxi9kHTjB\nd2tC1qkwpsVmAIh0BoQopfLPBTZoa9Eflif33S4WWjl88izH8wt4dqb9pHf/+z2bjMyZnDhTwBEv\nVuqyDQiXvLKIez5fE0Cu41dMBgAhhH+aPzbb7v2Hv+wgI3MmBV7OVbTcGGnschF74/GssAie+G5D\nccB54ydLiWGvTdfSvXmnuffz3zmW7xwQpnlY/Ut4Jyang5b1AIQIDuuc9vk+rm/rapK67i/8BFim\nm/ho6S62HzzJx7d0LS61v24zz5B139wTZ1i9y76u/5cs5yUYhe9iMwBEOgNCxBhfH6qO5XvXo2hd\ndh55p86x3Zig7nuTiejMbvbT3bQhCO9JFZAQwqO/v73Up/0Li7wLGHmnz/HUDBkTGikxGQCkBkiI\n4LJdnzjY8mW20IiJyQAghBDCs9gMAFICEKLUcLWmgQi9mAwAMhWEEEJ4FpMBQAghhGcxGQCkEVgI\nITyLzQAQ6QwIIUQpEJMBQAghhGcxGQBkKgghhPAsJgNAUkJMXpYQQgRVTN4pK5VNjnQWhBAi6sVk\nAAi1Aa1qRjoLQggRMAkAfnj7xk6RzkLU6tKwSqSzIITwkgSAMHhkUHOP+5xfvbzb7anJCUwe2Zlx\ng1vQu1m1YGUt6CqmSvWbEKVFXAeAS1pUd0r7YOQFTmkXZKQFdJ7RPRt73GfuvT3dbk9OTKBv8xrc\nenEjPhzVJaD8+KpWpdSwnk8IER4xHwAublLV5babumc4pfVp7hwUOtR3DgB1Kp9X/Pq1a9v7lzkb\nCQmKMkmuv44xfc+3e9+5QWBByRcPD2rhclvmQM+lGyFEdIr5AOBOYoKye//dnT1M97PdK8W4Sf88\ntk9xWv30sgCMG+z6RunOogd7A5BhHMeMYxWR7UiHO3o35rHLW/p1biuzko/VFW1rudx2dce6AZ1X\nCBE5MRsAqpQrA0D5FPtVL6/tXK/4dfdG6Xbb2tWrbH4wmwgw775eliRVktixfhrz7uvJLRc1LE5r\nWLWc6aG2PDPAKa1BejnjNMppmzceuKyZ3blHXpjB9V3r+3SMlOQENjzVnxHdGzhtU0oxaXhHpv6z\nm1/5E0JEJ48BQCk1WSl1QCm1wSatilJqnlJqq/F/mpGulFITlVJZSql1SqmONp8ZYey/VSk1IjSX\nU8JaRfPo4BZkDmxe3DtlaIfafHl7dz77Z1cSEry74SbY3Ozr2zylfz/mIr41Sg1NalSwCwrVKqSY\nHis1OdHleZKTLJ9/f0Tn4rQuGea9aqobx592W3enksyTQ1rx/N/amH7uz2cHmqZ3rJ9G+ZQknhra\nmjn39mTxg33stg9sU4vujdOdPpeUoPh8dDcua1nDxVXB6J6NXG4LRPdG6fyS2be4BCWE8I03i8J/\nCLwBTLFJywTma63HK6UyjfdjgYFAE+NfV2AS0FUpVQV4AuiMpfZilVJqutb6SLAuxNHkkRfw67aD\n1E0ry+29GrPwjwPF2y5wcVN1pWWtigC0rlPRLr11nUouP/PG9R34alU2t3loAL7cpnpl0vBOTF3x\nF31t2iHKpZgHjBevaUvf5tV97naZ5BAsNj3dn/xzRXaBqVnNCl4dSylIK1eGbo3SOXb6HHM37bfb\nXqVcGQ6fPOtT/nxR6bzk4kD/zR0Xsu3ACR78ap1Xnx3WpR5TV+wOWd6EKA08lgC01ouBww7JQ4GP\njNcfAVfapE/RFsuAykqpWkB/YJ7W+rBx058HONeFBFG1CikMbV/H434rx13C5W1rMeOui5y2PTKo\nOQ9c2pTkRMtN01pV443qFVK5o/f5Tk/n7tSrUpaHBjS3K0m4UjE1mb/bVGd5y/bQ393Zg7Jlkoqr\ny7zRsX5JNdmgNq7bBgCfjhuojvXTTH8eZcuUBLbqNqWyIe08/27YCue1CBEu/rYB1NBa7zVe7wOs\n5f86gO1jVbaR5io94qqWT+GN6zvSpq7z0/zono0Z068J/VrUYOSFGTw1pJVXx2xWw/0T9A/3XOzV\n2IBQUEox/qo2LHqwt+s2DxspDj2TvrmjB29c38Hyxss597ydnO9CkyomgBeuMq/OMhs7UTHVvlBr\nWxX3yj8svbUev7wl3RqZl5wq2LQZlSuTSNMa5fn6Xxcy/S7zDgJClGbeVAG5pbXWSqmgTb+plBoN\njAaoX9+3hsxQSU5M4Ekvb/7rn7yM5ET3cbVFrYr8uf84gFdP+8F2XRfvfq6ThnekZe2KTunWxuoi\nFzf24V3r8+nyv6hRMYWsAye8zpe7brBWH4y8gFEf/sZbwzuatjuM7tmIf8/90/SzFzWpys7xg90e\nv07aeRQUabIOnGDpI/3sBra9fUMnbv9klcc8ClFa+FsC2G9U7WD8b61gzwFsy+F1jTRX6U601u9q\nrTtrrTtXqxa5Ea++VN3YqpCa7Lah18raOyndQ9VCJCe2Htimlmm1lzW+2TaOX9ykGn2aVWPc4BY8\nPbQ1H9/ShV5NXX9/juMaPPn2zh5MubkLfZpXZ+f4wQxqU4skk0D7r972x1XAbb0aOfUGs3V7r8Z8\ndmvX4vef3NKVCde0dRrVfHGTqnRtWIX5D/TyKe9CRCt/A8B0wNqTZwTwnU36TUZvoG5AnlFVNAe4\nTCmVZvQYusxIi0qvXtuOufe5H5kbqL7Nq/PCVW1cDqRa8H+97Xri+NtFNBT6tajBiO4N7EpF55VJ\n5INRXcioWo7EBMXFTaoVl4SSEhN48gr7cQr3XdKUd27sRL0q5+GJ1tC+XmV6ugkoVraB+6qOdXhr\neCceHtiCDU/1d/mZzIHNqVy2JBDXrJRq2p5QLiWJL27rTuNq7qftEKK08FgFpJSaCvQGqiqlsrH0\n5hkPTFNK3QLsAv5h7D4LGARkAaeAUQBa68NKqWeA34z9ntZaOzYsh9T1XRuwbPthj3PuAPytQ+gH\nNymlGOamKsbVOAJ3Zt19semTbqvaFdm455jPx3MlOTGBp4a29rjfsC712ZuXz119zqdcShJPzthU\nvC0hQdG/VU36t6pJRubMoOXNlrXOXwhhzmMA0FoPc7Gpn8m+GrjTxXEmA5N9yl0QDWlXmyHtakfq\n9GFhVl8PlrrvVrUrclWYR+2mJifyiJtpJKLBoDYytbeIXwE3Aovop1C8dE27SGfDb77epBc/2Iec\no6c97rdy3CXF9fx10ixVUaOkkZ5SAAAURElEQVR6ZPicPyF8dd8lTXn1R/POCuEUs1NBiOjVwM2c\nR2Zs6+e9UT+9rOmoZUdVy6cU9zyqdF4yO8cP5toLoqPnmQi+QGf1DaYr2rkfQxMuUgIIkx/uudjv\nnkWBikBPU7ccfw63XNSQMwWFZB+xPLW/fUMnujasQodn5kUieyIGPXZ5S27ukUHDh2d5/ZnqFVKY\n8Pd2ZB85xaP/2+C0PUFBkZ/d9OpV8e0hKFSkBBAmLWpVpKmHAWLB9mD/ZmE9n9cc/mgeu7wlz15Z\nMtirTJIiTUbeiiC65aKGpmNuXE2r3qZOJebd14teTasxvGsDZt97MbcaEy7ee0kTANrWrcwzQz2P\nDzKbrsXTWKFwiY5ciJD4e6e6NKlenhu6Oc/wWRq8d1NnnrnSc2+j0qytyQj0YGjvxSjvWHVXH+/H\nmDR1mPeqjHFjrl+lLJXKlowDaV6zIuMub8nO8YO5s8/5DG5biwnXtOXG7hmmgwtfv6693aSOnjiO\nuAfoUD/036EEgBhWvWIq8+7vZbd4TTQo62KCO8fns0ta1uDGKA9ebw3v6Hb7le0tPc9uvaghk0d6\nd0MonmrDhqvZZV351sXaFvFgsDHBouPEh2YubVmDj27uwopH+9G1YRXuMZ7u3UlOTODN6zvSxE2J\nvkO9NNoYk0Ve3bFk1pthXczn70owKZ2Eo+ZWAoAIu3dvNL8RphmNvalJnkdSRwtPE+K1ql3yhN+r\naXVuvaih3Wyvt/dqzK+ZfYvffz/mIi5vW9urm5e3HKcUH3lhRtCOXdopoFfTalSvkMoXt3UvqZv3\n8cfvuI5GkdZUr5jq1LHg+b+1YfvzgwD4YNQF3NbLMlW67f0/nEuwSgAQYVfbRYnkqaGteGpIK696\n8EST4W4W3+nYwFKMv/D8dBITFOMub8lr15UMUBvUppbdz8M6xfj9lzW1O45ZFYG3xg5sZrfa3FUd\no2Iexoh658ZOQMlU7458Db9PDW1NOzfVefWrlOVvHeqglCpeh6RPs+pOi1IBdGyQ5nYp22CSACCi\nRoXUZEZcmBGRCfIC8cQVrexWmrPVqUEVNj3dn77NSyaus9Yzpya7/vO7o/f5djObDmhVMhbCrG55\nys1dnNK+vbMHA1vXpKPDmtbRNK1IpPRvVZOd4wdTvaL903aPxulUTE3yuI6HmY9v7crTQ1vRuUFa\n8bgSq8UP9eFVN2uHt64dmrYgTyQACBGgMkkJpj09rCPPy5ax722dmpzI7HsvZvVjl3p1/A9GXsDD\nNiOq+7VwngXVrNTUvl5lJt3QCaUUI2yqfWy74XZy0QumNLNe3987+z7yPb18Cuue7G86PbwnFVOT\nual7Bl/960Kfe/mk2DwMNAhjF1EJAEIEQY/z7Yvs1SukuJ0Go3nNik6BwZWO9dPcjiH5702dSU5M\nsCslOBrVoyEL/683jw5qQYtaJY2XsVgdlKBg41P97boWRyvb0q51Ysj7Lm3qavegk4FgQgRBzUqW\nBj/rxHYrHr3E52P4W+9rvYV4GmiYUbUc/3RYn9nLtXpKGUU5F9N/j7wwg0rnJZtuiwRrY39KUiK3\n92rM7b18r3oK6PxhPZvwWWz+gQpHfzw7gKQE+wL5hY2rMnvjPpKTSm7stU16iATSZBJvv17eLuwU\nLt0bpTOm7/l2VXThJAGgtJB2u5iWYtL19bXr2pNz9HRxVdGKR/pxnrHG8e29GvPpsl0cP1NQ3Ie8\ndmVLcPCmm2evptVY9GdukHIv/JWQoHjgssiN2JcAIESUSk1OtFt8xrbHSubA5mzae4zFf+YWPxz8\nX/9mtK1bmcvbep5o7COj19Any3YFN9NR5vPR3dh9+FSksxG1JAAIUUpZ67KtA+dSkhK5IsbXvPBV\nt0bpdDPpay8sJAAIUUo9e2VrOtavTLdGzl1QvRVvbQDCnnQDFSKI6lQ+L2xP4ZXOS2ZUD/NZLr0W\n4V4GvWzWef7sn12DcsxSNo4woiQACBFEv2T25T/DnCdzi1dv3+A8Wd4r/3Bene6DkRdwYePwTH8g\nSkgAEEL4ZbTDmAIzA1o7N0ib9sM3ntofGdTc5bF6N6vmcpvwjwQAIYRfAq1psZ0V1Wp0z8ZM/Wc3\n0/2HdanPj/f3pILNIC/rbJrCPxIAhIhjrkbM+spsURRv/K2DZSoK29XyujdOZ+f4wYwb7DyVxvnV\nK/CZESC6N0rn4YGup9sQnkkAECKOWatjepzv3FXS45KiPhQBbCfLs213vrJDHXaOH2y6aFFNh1HP\n1tO1qVuJneMHM3W0eUlBeE8CgBCClKREqpYvwx29S+aiub1XYz671b5nztz7ejLr7osBuKl7ht22\nf7iYfXPn+MFMu607ax6/lDWPl8yAKp11Ik/GAQghAFg5znJzfmvhNsAyudyFNrOcPnFFS5pUL49S\nqrjKp0WtipQ3lvh86Zp2PPe3Ntz12WoGt61NqsMiNpWNFd9E9JAAIITwyqgeDZ3SfrjnYrv3yYkJ\nvONiyc9AlU91f7tqVLUc2w+eDMm5Y1VAAUApdR9wK5YBheuBUUAt4HMgHVgF3Ki1PquUSgGmAJ2A\nQ8C1WuudgZxfCBF6n/2zK8dOnwv7ea0rl/VtXp0h7WqbLp8oAuN3G4BSqg5wN9BZa90aSASuA14E\nXtVanw8cAW4xPnILcMRIf9XYTwgRQd4MBL6wcVXT/vzhkpqcwJXGeroiuAJtBE4CzlNKJQFlgb1A\nX+ArY/tHwJXG66HGe4zt/ZR8ox7JXC0iHBz/EJMTI/+n2aaOZVnGITLBXcj4XQWktc5RSv0b+As4\nDczFUuVzVGtdYOyWDVjXnKsD7DY+W6CUysNSTXTQ3zwIIYJvyUN9KFvGeX2CYKlnrHlrto6yrfrp\nZX0aXyAPS77zOwAopdKwPNU3BI4CXwIDAs2QUmo0MBqgfv36gR6u1Iv8c5iIN/VCvCh5s5oVWPJQ\nH+qmOff9D4ZY+ZsJR0ALpAroEmCH1jpXa30O+AboAVQ2qoQA6gI5xuscoB6Asb0SlsZgO1rrd7XW\nnbXWnatVk7k/hIhF9aqUlTr9KBBIAPgL6KaUKmvU5fcDNgELgGuMfUYA3xmvpxvvMbb/pLWseCtE\nJMkfYHzzOwBorZdjacxdjaULaALwLjAWuF8plYWljv994yPvA+lG+v1AZgD5FkIEkTyMx6eAxgFo\nrZ8AnnBI3g50Mdk3H/h7IOcTQghHr1/XnkZVy3P3579HOiuljowEFkKUakPb1/G8kzAlk8EJIWKC\nNCn6TgKAEHEsFm+a0rvIexIAhBDETu954QsJAEIIEackAAghRJySACCEEHFKAoAQcSyWmoBj6VrC\nRQKAECKmRgLH0KWEnASAKCdPNUKIUJEAUErIU40QItgkAAghRJySACBEHIvBgcDCBxIAhBBSxRin\nJAAIIWKClGZ8JwFACBFTYqlLa6hJABAirsljczyTACCEkKfmOCUBQAgh4pQEACGEiFMSAIQQIk5J\nABAijsVS10ktDdo+kwAghIgpSoa1eU0CgBBxTHr/xDcJAEIIEackAEQ5HUuVtEKIqBJQAFBKVVZK\nfaWU2qKU2qyU6q6UqqKUmqeU2mr8n2bsq5RSE5VSWUqpdUqpjsG5hPigpKwuQkCeL+JboCWA14HZ\nWuvmQDtgM5AJzNdaNwHmG+8BBgJNjH+jgUkBnlsIESSx0HAqwcx3fgcApVQloCfwPoDW+qzW+igw\nFPjI2O0j4Erj9VBgirZYBlRWStXyO+dCCGFCCsveC6QE0BDIBT5QSv2ulHpPKVUOqKG13mvssw+o\nYbyuA+y2+Xy2kSaEECICAgkASUBHYJLWugNwkpLqHgC0pQXTp4KZUmq0UmqlUmplbm5uANkTQgjh\nTiABIBvI1lovN95/hSUg7LdW7Rj/HzC25wD1bD5f10izo7V+V2vdWWvduVq1agFkTwjhiVSbxze/\nA4DWeh+wWynVzEjqB2wCpgMjjLQRwHfG6+nATUZvoG5Ank1VkRAigqTePD4lBfj5McCnSqkywHZg\nFJagMk0pdQuwC/iHse8sYBCQBZwy9hVCCBEhAQUArfUaoLPJpn4m+2rgzkDOJ4QQInhkJLAQQsQp\nCQBCxDEZPBXfJAAIIaQROE5JABBCiDglAUAIIeKUBAAhREyQ9gzfSQAQIo7JOrrxTQJAKSFtdCKU\nYmE6aOE7CQBCCBGnJAAIIUSckgAghBBxSgKAEHFMes7ENwkAQgjpZRCnJAAIIWKKTGvhPQkAQggR\npyQACCFEnJIAIEQckzbg+CYBQAghbcBxSgKAECImaOnT6jMJAEKImKKkG5DXJAAIIUScSop0BkT8\nWPFIP46ePhfpbAgbUm0S3yQAiLCpXjGV6hVTI50NYUKqTeKTVAFFOXlAE0KEigSAUkIe0IQQwSYB\nQAgRE6Sw7DsJAEKImCKFZe8FHACUUolKqd+VUt8b7xsqpZYrpbKUUl8opcoY6SnG+yxje0ag5xZC\nBIfcNONTMEoA9wCbbd6/CLyqtT4fOALcYqTfAhwx0l819hNCCBEhAQUApVRdYDDwnvFeAX2Br4xd\nPgKuNF4PNd5jbO+npO+ZEEJETKAlgNeAh4Ai4306cFRrXWC8zwbqGK/rALsBjO15xv52lFKjlVIr\nlVIrc3NzA8yeEEIIV/wOAEqpy4EDWutVQcwPWut3tdadtdadq1WrFsxDCyEcxNI4k1i6lnAJZCRw\nD2CIUmoQkApUBF4HKiulkoyn/LpAjrF/DlAPyFZKJQGVgEMBnF8IESSxVBkbC9cy4Zp2FIUhovld\nAtBaP6y1rqu1zgCuA37SWg8HFgDXGLuNAL4zXk833mNs/0nLRCRCCOGkZqVUalc+L+TnCcU4gLHA\n/UqpLCx1/O8b6e8D6Ub6/UBmCM4thBDCS0GZDE5rvRBYaLzeDnQx2Scf+HswzieEECJwMhJYiDjW\nt0V12tSpxN39mkQ6KyICZDpoIeJYxdRkZoy5KNLZEBEiJQAhREzQMh2cz6QEEOUeGtCMPV+cpkP9\ntEhnRdjo1qgKl7SoEelsCBNKZjbymgSAKNe2bmV+eqB3pLMhHHw+unuksyBEwKQKSAgh4pQEACGE\niFMSAIQQIk5JABBCxITzkhOB2JgLKFykEVgIEROm3NyVGev2UL1CSqSzUmpIABBCxIT66WW5s8/5\nkc5GqSJVQEIIEackAAghRJySACCEEHFKAoAQQsQpCQBCCBGnJAAIIUSckgAghBBxSgKAEELEKaV1\n9C6ioJTKBXYFcIiqwMEgZSdS5Bqig1xD9IiF6wj1NTTQWlfztFNUB4BAKaVWaq07RzofgZBriA5y\nDdEjFq4jWq5BqoCEECJOSQAQQog4FesB4N1IZyAI5Bqig1xD9IiF64iKa4jpNgAhhBCuxXoJQAgh\nhAsxGQCUUgOUUn8opbKUUpmRzo8jpdROpdR6pdQapdRKI62KUmqeUmqr8X+aka6UUhONa1mnlOpo\nc5wRxv5blVIjQpznyUqpA0qpDTZpQcuzUqqT8TPJMj4bknWdXFzHk0qpHOP7WKOUGmSz7WEjT38o\npfrbpJv+jimlGiqllhvpXyilygQ5//WUUguUUpuUUhuVUvcY6aXqu3BzHaXpu0hVSq1QSq01ruEp\nd+dVSqUY77OM7Rn+XlvQaK1j6h+QCGwDGgFlgLVAy0jnyyGPO4GqDmkvAZnG60zgReP1IOAHQAHd\ngOVGehVgu/F/mvE6LYR57gl0BDaEIs/ACmNfZXx2YBiv40ng/0z2bWn8/qQADY3fq0R3v2PANOA6\n4/XbwL+CnP9aQEfjdQXgTyOfpeq7cHMdpem7UEB543UysNz4uZmeF7gDeNt4fR3whb/XFqx/sVgC\n6AJkaa23a63PAp8DQyOcJ28MBT4yXn8EXGmTPkVbLAMqK6VqAf2BeVrrw1rrI8A8YECoMqe1Xgwc\nDkWejW0VtdbLtOUvYorNscJxHa4MBT7XWp/RWu8AsrD8fpn+jhlPyn2Br4zP2/5MgpX/vVrr1cbr\n48BmoA6l7Ltwcx2uRON3obXWJ4y3ycY/7ea8tt/RV0A/I58+XVswryEWA0AdYLfN+2zc/2JFggbm\nKqVWKaVGG2k1tNZ7jdf7gBrGa1fXEw3XGaw81zFeO6aH011GFclka/UJvl9HOnBUa13gkB4SRhVC\nByxPnqX2u3C4DihF34VSKlEptQY4gCWIbnNz3uK8GtvzjHxG7G88FgNAaXCR1rojMBC4UynV03aj\n8eRVqrpnlcY825gENAbaA3uBlyObHc+UUuWBr4F7tdbHbLeVpu/C5DpK1XehtS7UWrcH6mJ5Ym8e\n4Sz5JBYDQA5Qz+Z9XSMtamitc4z/DwD/w/KLs98ofmP8f8DY3dX1RMN1BivPOcZrx/Sw0FrvN/6Q\ni4D/Yvk+wPfrOISliiXJIT2olFLJWG6an2qtvzGSS913YXYdpe27sNJaHwUWAN3dnLc4r8b2SkY+\nI/c3HswGhWj4ByRhadBqSEnDSatI58smf+WACjavf8VSdz8B+0a8l4zXg7FvxFthpFcBdmBpwEsz\nXlcJcd4zsG88DVqecW54HBTG66hl8/o+LPWxAK2wb5zbjqVhzuXvGPAl9g2AdwQ57wpLvfxrDuml\n6rtwcx2l6buoBlQ2Xp8HLAEud3Ve4E7sG4Gn+XttQbuGUP2RRfIflp4Pf2Kpj3s00vlxyFsj44tc\nC2y05g9LXeB8YCvwo80fowLeNK5lPdDZ5lg3Y2kwygJGhTjfU7EUyc9hqYu8JZh5BjoDG4zPvIEx\nSDFM1/Gxkc91wHSHm9CjRp7+wKY3jKvfMeP7XWFc35dASpDzfxGW6p11wBrj36DS9l24uY7S9F20\nBX438roBeNzdeYFU432Wsb2Rv9cWrH8yElgIIeJULLYBCCGE8IIEACGEiFMSAIQQIk5JABBCiDgl\nAUAIIeKUBAAhhIhTEgCEECJOSQAQQog49f+WII/OWtaAVgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOHJrTPJYacM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model to '/gdrive/My Drive/model.pt'\n",
        "model = Verify_Assumption_Model()\n",
        "torch.save(model.state_dict(), '/gdrive/My Drive/model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUrRHEwDY7Ms",
        "colab_type": "code",
        "outputId": "e7b348e2-4cfb-4a87-ec07-a71aa0384171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load model from state_dict file '/gdrive/My Drive/model.pt'\n",
        "model = Verify_Assumption_Model()\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/model.pt', map_location='cpu'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al6Ikk9rZiSx",
        "colab_type": "code",
        "outputId": "618733ea-5b80-44c3-f401-25dda64eef96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_save_name = 'model.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/model.pt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZzUHxc8exeV",
        "colab_type": "code",
        "outputId": "5a61d609-0752-4d27-e359-2d7ef22f86b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cpu')\n",
        "model = Verify_Assumption_Model()\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/model.pt', map_location=device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oY9f4RSfzsC",
        "colab_type": "code",
        "outputId": "16ec4e73-c79e-4f03-92c9-bb2ed0489ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = Verify_Assumption_Model()\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/model.pt'), strict=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzyFOoesJYgh",
        "colab_type": "text"
      },
      "source": [
        "**4.5 Analyse des résultats et évaluation**\n",
        "\n",
        "Nous pouvons voir que la perte de test diminue lentement puis augmente lentement. Cela suppose que nous obtiendrons un meilleur résultat en modifiant les paramètres. Cependant, étant donné que le temps d’entraînement est trop long, il n’y a pas assez de temps pour modifier différents paramètres pour l’expérimentation. Nous le ferons plus tard.\n",
        "La performance de ce modèle est donc bonne, et cela peut nous aider à vérifier l’hypothèse: le vecteur de pertinence peut représenter des films."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB22tX6rJ7CW",
        "colab_type": "text"
      },
      "source": [
        "**5 système de recommandation**\n",
        "\n",
        "Sur la base du modèle présenté au chapitre 4, nous pouvons créer un système de recommandation capable de:\n",
        "\n",
        "\n",
        "1.   Donner une liste de films liés à un film;\n",
        "2.   prédire les films préférés des utilisateurs;\n",
        "3.   Recommander des films pertinents que l'utilisateur souhaite et que l'utilisateur vient de regarder.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waioCEpiKkNP",
        "colab_type": "text"
      },
      "source": [
        "**5.1 Recommander des films pertinents**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOLXGFmUUhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "def get_relevant_movies(id, orginal=True, movie_num=10):\n",
        "    \n",
        "    movie_feature = []\n",
        "    movie_id = []\n",
        "    movie_num += 1 # because the most relevant movie is the same movie.\n",
        "    \n",
        "    # Get all movie vector, You can run quickly if you save the movie vector in your memory.\n",
        "    for key in genome_scores_dict.keys():\n",
        "        movie_id.append(key)\n",
        "        if orginal:     \n",
        "            norm = np.linalg.norm(genome_scores_dict[key],ord=2) \n",
        "            movie_feature.append(genome_scores_dict[key]/norm)\n",
        "        else:\n",
        "            v = model.movie_transfrom(torch.tensor(genome_scores_dict[key]).cuda()).cpu().detach().numpy()\n",
        "            norm = np.linalg.norm(v,ord=2) \n",
        "            movie_feature.append(v/norm)\n",
        "\n",
        "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
        "\n",
        "    if orginal: \n",
        "        norm = np.linalg.norm(genome_scores_dict[str(id)],ord=2)\n",
        "        in_movie = torch.tensor(genome_scores_dict[str(id)]/norm).expand(10381, 1128).unsqueeze_(2).cuda()\n",
        "    else:\n",
        "       # v = model.movie_transfrom(torch.tensor(genome_scores_dict[str(id)]).cuda()).cpu().detach().numpy()\n",
        "        v = model.movie_transfrom(torch.tensor(genome_scores_dict[str(id)]).cuda()).cpu().detach().numpy()\n",
        "        norm = np.linalg.norm(v,ord=2)\n",
        "        in_movie = torch.tensor(v/norm).cuda().expand(10381, 512).unsqueeze_(2)\n",
        "    \n",
        "    similarity = torch.bmm(movie_feature,in_movie).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
        "    index = np.argpartition(similarity, -movie_num)[-movie_num:]\n",
        "    \n",
        "    if orginal: \n",
        "        print('Find relevant movies based on relevance vector from genome-scores.csv')\n",
        "    else:\n",
        "        print('Find relevant movies based on movie feature vector from training model')\n",
        "    \n",
        "    print('')\n",
        "    print('Input Movie: {}'.format(movies[movies['movieId']==id].values[0]))\n",
        "    print('')\n",
        "    print('Relevant Movie:')\n",
        "    \n",
        "    re = []\n",
        "    for i in index:\n",
        "        if movie_id[i] != str(id):\n",
        "            print('    {}'.format(movies[movies['movieId']==int(movie_id[i])].values[0]))\n",
        "            re.append(movie_id[i])\n",
        "            \n",
        "    return re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UALxoBAM7-L",
        "colab_type": "text"
      },
      "source": [
        "**Analyser le résultat sur la prochaine cellule **\n",
        "\n",
        "Nous présentons ici la recherche de film pertinente basée sur le modèle d’apprentissage automatique et le vecteur de pertinence de genome_scores.csv. Nous constatons que les deux méthodes peuvent trouver des films pertinents, et il existe un certain chevauchement entre les deux méthodes. Je pense que le vecteur de caractéristiques de film du modèle est proche du vecteur de pertinence de genome_scores.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFOIQt3AUbas",
        "colab_type": "code",
        "outputId": "981dcfe2-9959-4c83-8d71-a00ee19844f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "get_relevant_movies(2,True)\n",
        "print('')\n",
        "print('--------------------------------')\n",
        "print('')\n",
        "get_relevant_movies(2,False)\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find relevant movies based on relevance vector from genome-scores.csv\n",
            "\n",
            "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
            "\n",
            "Relevant Movie:\n",
            "    [2047 'Gnome-Mobile, The (1967)' 'Adventure|Children|Fantasy|Musical']\n",
            "    [1920 'Small Soldiers (1998)' 'Animation|Children|Fantasy|War']\n",
            "    [480 'Jurassic Park (1993)' 'Action|Adventure|Sci-Fi|Thriller']\n",
            "    [7781 'Twister (1990)' 'Comedy']\n",
            "    [455 'Free Willy (1993)' 'Adventure|Children|Drama']\n",
            "    [40851 'Zathura (2005)' 'Action|Adventure|Children|Fantasy']\n",
            "    [2429 'Mighty Joe Young (1998)' 'Action|Adventure|Drama|Fantasy|Thriller']\n",
            "    [46972 'Night at the Museum (2006)' 'Action|Comedy|Fantasy|IMAX']\n",
            "    [2054 'Honey, I Shrunk the Kids (1989)'\n",
            " 'Adventure|Children|Comedy|Fantasy|Sci-Fi']\n",
            "    [1848 'Borrowers, The (1997)' 'Adventure|Children|Comedy|Fantasy']\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "Find relevant movies based on movie feature vector from training model\n",
            "\n",
            "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
            "\n",
            "Relevant Movie:\n",
            "    [119155 'Night at the Museum: Secret of the Tomb (2014)'\n",
            " 'Adventure|Children|Comedy|Fantasy']\n",
            "    [1920 'Small Soldiers (1998)' 'Animation|Children|Fantasy|War']\n",
            "    [40851 'Zathura (2005)' 'Action|Adventure|Children|Fantasy']\n",
            "    [1702 'Flubber (1997)' 'Children|Comedy|Fantasy']\n",
            "    [1848 'Borrowers, The (1997)' 'Adventure|Children|Comedy|Fantasy']\n",
            "    [2015 'Absent-Minded Professor, The (1961)' 'Children|Comedy|Fantasy']\n",
            "    [46972 'Night at the Museum (2006)' 'Action|Comedy|Fantasy|IMAX']\n",
            "    [2429 'Mighty Joe Young (1998)' 'Action|Adventure|Drama|Fantasy|Thriller']\n",
            "    [2047 'Gnome-Mobile, The (1967)' 'Adventure|Children|Fantasy|Musical']\n",
            "    [2054 'Honey, I Shrunk the Kids (1989)'\n",
            " 'Adventure|Children|Comedy|Fantasy|Sci-Fi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEHVzDFGxViF",
        "colab_type": "text"
      },
      "source": [
        "**Prédire à un utilisateur ses films préférés**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTIdoPgRxa-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def guess_your_favourite(userId, movie_num=10):\n",
        "    \n",
        "    user_vector = model.emb_user(torch.tensor([userId]).cuda()).expand(10381, 512).unsqueeze_(2).cuda()\n",
        "    \n",
        "    movie_feature = []\n",
        "    movie_id = []\n",
        "    for key in genome_scores_dict.keys():\n",
        "        movie_id.append(key)\n",
        "        movie_feature.append(model.movie_transfrom(torch.tensor(genome_scores_dict[key]).cuda()).cpu().detach().numpy())\n",
        "\n",
        "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
        "\n",
        "    favourite_v = torch.bmm(movie_feature,user_vector).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
        "    index = np.argpartition(favourite_v, -movie_num)[-movie_num:]\n",
        "    \n",
        "    \n",
        "    print('Find your top{} favourite movies'.format(movie_num))\n",
        "    \n",
        "    print('')\n",
        "    print('Favourite Movie:')\n",
        "    \n",
        "    re = []\n",
        "    for i in index:\n",
        "        if movie_id[i] != str(id):\n",
        "            print('    {}'.format(movies[movies['movieId']==int(movie_id[i])].values[0]))\n",
        "            re.append(movie_id[i])\n",
        "            \n",
        "    print('')\n",
        "    print('The rating of these movies by user {}'.format(userId))\n",
        "    \n",
        "    for i in re:\n",
        "        result = ratings[(ratings['movieId']==int(i))&(ratings['userId']==userId)].values\n",
        "        if len(result) > 0:\n",
        "            print('    Movie ({:>5}). Rating: {}'.format(i, result[0][2]))\n",
        "        else:\n",
        "            print('    There is no rating on this movie ({:>6}) by user.'.format(i))\n",
        "    return re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MiYU84Qx4vg",
        "colab_type": "text"
      },
      "source": [
        "**Analysis the result on next code cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ke49AJKxx26",
        "colab_type": "code",
        "outputId": "d5d4dddf-6655-40d8-850c-57b33080158e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "guess_your_favourite(7)\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find your top10 favourite movies\n",
            "\n",
            "Favourite Movie:\n",
            "    [4973 \"Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\"\n",
            " 'Comedy|Romance']\n",
            "    [2324 'Life Is Beautiful (La Vita è bella) (1997)'\n",
            " 'Comedy|Drama|Romance|War']\n",
            "    [7949 'Yakuza, The (1975)' 'Drama']\n",
            "    [4173 'When Brendan Met Trudy (2000)' 'Comedy|Romance']\n",
            "    [1198\n",
            " 'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)'\n",
            " 'Action|Adventure']\n",
            "    [31923 'Three Musketeers, The (1973)' 'Action|Adventure|Comedy']\n",
            "    [912 'Casablanca (1942)' 'Drama|Romance']\n",
            "    [48394 \"Pan's Labyrinth (Laberinto del fauno, El) (2006)\"\n",
            " 'Drama|Fantasy|Thriller']\n",
            "    [1265 'Groundhog Day (1993)' 'Comedy|Fantasy|Romance']\n",
            "    [1197 'Princess Bride, The (1987)'\n",
            " 'Action|Adventure|Comedy|Fantasy|Romance']\n",
            "\n",
            "The rating of these movies by user 7\n",
            "    There is no rating on this movie (  4973) by user.\n",
            "    There is no rating on this movie (  2324) by user.\n",
            "    There is no rating on this movie (  7949) by user.\n",
            "    There is no rating on this movie (  4173) by user.\n",
            "    There is no rating on this movie (  1198) by user.\n",
            "    There is no rating on this movie ( 31923) by user.\n",
            "    Movie (  912). Rating: 5.0\n",
            "    There is no rating on this movie ( 48394) by user.\n",
            "    Movie ( 1265). Rating: 4.0\n",
            "    There is no rating on this movie (  1197) by user.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EjLh1UF1RZg",
        "colab_type": "text"
      },
      "source": [
        "**Recommander une suite de films à l'utilisateur connaissant un film de son choix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfLHKQFV1g2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recommand_relevant_movies_you_may_like(movieId, userId, movie_num=5):\n",
        "    \n",
        "    # The first part code copy from get_relevant_movies\n",
        "    \n",
        "    movie_feature = []\n",
        "    movie_id = []\n",
        "    \n",
        "    # Get all movie vector, You can run quickly if you save the movie vector in your memory.\n",
        "    for key in genome_scores_dict.keys():\n",
        "        movie_id.append(key)\n",
        "        norm = np.linalg.norm(genome_scores_dict[key],ord=2) \n",
        "        movie_feature.append(genome_scores_dict[key]/norm)\n",
        "\n",
        "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
        " \n",
        "    norm = np.linalg.norm(genome_scores_dict[str(movieId)],ord=2)\n",
        "    in_movie = torch.tensor(genome_scores_dict[str(movieId)]/norm).expand(10381, 1128).unsqueeze_(2).cuda()\n",
        "    \n",
        "    similarity = torch.bmm(movie_feature,in_movie).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
        "    index = np.argpartition(similarity, -51)[-51:]\n",
        "    \n",
        "    re = []\n",
        "    \n",
        "    # The Second part code copy from guess_your_favourite\n",
        "            \n",
        "    user_vector = model.emb_user(torch.tensor([userId]).cuda()).expand(50, 512).unsqueeze_(2).cuda()\n",
        "    \n",
        "    movie_feature = []\n",
        "    movie_id2 = []\n",
        "    \n",
        "    for i in index:\n",
        "        if movie_id[i] != str(movieId):\n",
        "            movie_id2.append(movie_id[i])\n",
        "            movie_feature.append(model.movie_transfrom(torch.tensor(genome_scores_dict[movie_id[i]]).cuda()).cpu().detach().numpy())\n",
        "            \n",
        "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
        "\n",
        "    favourite_v = torch.bmm(movie_feature,user_vector).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
        "    index = np.argpartition(favourite_v, -movie_num)[-movie_num:]\n",
        "    \n",
        "    print('Input Movie: {}'.format(movies[movies['movieId']==movieId].values[0]))\n",
        "    print('User {} may like these {} relevant movies: '.format(userId, movie_num))\n",
        "    \n",
        "    print('')\n",
        "    print('Recommand List:')\n",
        "    \n",
        "    re = []\n",
        "    for i in index:\n",
        "        if movie_id2[i] != str(id):\n",
        "            print('    {}'.format(movies[movies['movieId']==int(movie_id2[i])].values[0]))\n",
        "            re.append(movie_id2[i])\n",
        "            \n",
        "    print('')\n",
        "    print('The rating of these movies by user {}: '.format(userId))\n",
        "    \n",
        "    for i in re:\n",
        "        result = ratings[(ratings['movieId']==int(i))&(ratings['userId']==userId)].values\n",
        "        if len(result) > 0:\n",
        "            print('    Movie ({:>3}). Rating: {}'.format(i, result[0][2]))\n",
        "        else:\n",
        "            print('    There is no rating on this movie ({:>5}) by user.'.format(i))\n",
        "            \n",
        "    return re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32mdmwG1vmP",
        "colab_type": "text"
      },
      "source": [
        "**Analysis the result on next code cell**\n",
        "\n",
        "Analysons le résultat sur la prochaine cellule\n",
        "\n",
        "1.   nous pouvons constater que les films recommandés sont similaires au film d'entrée.\n",
        "2.    les films recommandés ne sont pas exactement les mêmes que ceux des chapitres 5.1 et 5.2. Le résultat du chapitre 5.1 base sur movie id = 2 et le résultat du chapitre 5.2 base sur user id = 7. Le résultat ici base sur movie id = 2 et utilisateur id = 7.\n",
        "3.   Le classement des films recommandés est relativement élevé.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3sPKVc514J9",
        "colab_type": "code",
        "outputId": "cd59cea5-be36-42a7-a9cb-96ad90328623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "recommand_relevant_movies_you_may_like(2, 7, movie_num=5)\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
            "User 7 may like these 5 relevant movies: \n",
            "\n",
            "Recommand List:\n",
            "    [480 'Jurassic Park (1993)' 'Action|Adventure|Sci-Fi|Thriller']\n",
            "    [2617 'Mummy, The (1999)'\n",
            " 'Action|Adventure|Comedy|Fantasy|Horror|Thriller']\n",
            "    [3489 'Hook (1991)' 'Adventure|Comedy|Fantasy']\n",
            "    [2015 'Absent-Minded Professor, The (1961)' 'Children|Comedy|Fantasy']\n",
            "    [43869 'Curious George (2006)' 'Adventure|Animation|Children|Comedy']\n",
            "\n",
            "The rating of these movies by user 7: \n",
            "    Movie (480). Rating: 5.0\n",
            "    There is no rating on this movie ( 2617) by user.\n",
            "    There is no rating on this movie ( 3489) by user.\n",
            "    There is no rating on this movie ( 2015) by user.\n",
            "    There is no rating on this movie (43869) by user.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU3xwHoF-5cm",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "`*Dificultés et perspectifs*`\n",
        "\n",
        "Si le vecteur de pertinence de genome_scores.csv représente des films, nous avons besoin de plus de vecteur de pertinence, car l'ensemble des données ne contient que 53,0% de films avec un vecteur de pertinence. Donc, je pense qu'à l'avenir, nous pourrons faire le travail suivant:\n",
        "\n",
        "1.   Construisez un vecteur de pertinence de modèle prédit pour les films. Il peut s'agir d'un modèle d'apprentissage automatique ou de modèles tels que le modèle d'origine.\n",
        "2.   La prévision des évaluations des utilisateurs peut ne pas être la meilleure façon de mettre en œuvre le système de recommandation. Nous devrions essayer d'autres méthodes.\n",
        "\n",
        "\n",
        "3.   Le vecteur de pertinence peut ne pas être le meilleur moyen de représenter un film. Nous devrions également essayer d'autres méthodes.\n",
        "4.   Obtenez plus de données sur Internet via link.csv pour construire un modèle tenant compte de l’ensemble des avis des utilisateurs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}